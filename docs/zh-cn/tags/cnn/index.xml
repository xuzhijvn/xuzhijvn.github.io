<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CNN on 🇨🇳🇨🇳🇨🇳🇨🇳🇨🇳</title>
    <link>https://xuzhijvn.github.io/zh-cn/tags/cnn/</link>
    <description>Recent content in CNN on 🇨🇳🇨🇳🇨🇳🇨🇳🇨🇳</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2016-{year} Razon Yang. All Rights Reserved.</copyright>
    <lastBuildDate>Fri, 27 Aug 2021 11:15:10 +0800</lastBuildDate><atom:link href="https://xuzhijvn.github.io/zh-cn/tags/cnn/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>卷积神经网络</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/ai/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Ccnn/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/ai/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Ccnn/</guid>
      <description>在 CNN 出现之前，图像对于人工智能来说是一个难题，有2个原因：
 图像需要处理的数据量太大，导致成本很高，效率很低 图像在数字化的过程中很难保留原有的特征，导致图像处理的准确率不高  下面就详细说明一下这2个问题：
需要处理的数据量太大 图像是由像素构成的，每个像素又是由颜色构成的。
现在随随便便一张图片都是 1000×1000 像素以上的， 每个像素都有RGB 3个参数来表示颜色信息。
假如我们处理一张 1000×1000 像素的图片，我们就需要处理3百万个参数！
1000×1000×3=3,000,000
这么大量的数据处理起来是非常消耗资源的，而且这只是一张不算太大的图片！
卷积神经网络 – CNN 解决的第一个问题就是「将复杂问题简化」，把大量参数降维成少量参数，再做处理。
更重要的是：我们在大部分场景下，降维并不会影响结果。比如1000像素的图片缩小成200像素，并不影响肉眼认出来图片中是一只猫还是一只狗，机器也是如此。
保留图像特征 图片数字化的传统方式我们简化一下，就类似下图的过程：
假如有圆形是1，没有圆形是0，那么圆形的位置不同就会产生完全不同的数据表达。但是从视觉的角度来看，图像的内容（本质）并没有发生变化，只是位置发生了变化。
所以当我们移动图像中的物体，用传统的方式的得出来的参数会差异很大！这是不符合图像处理的要求的。
而 CNN 解决了这个问题，他用类似视觉的方式保留了图像的特征，当图像做翻转，旋转或者变换位置时，它也能有效的识别出来是类似的图像。
那么卷积神经网络是如何实现的呢？在我们了解 CNN 原理之前，先来看看人类的视觉原理是什么？
1. 人类的视觉原理 深度学习的许多研究成果，离不开对大脑认知原理的研究，尤其是视觉原理的研究。
1981 年的诺贝尔医学奖，颁发给了 David Hubel（出生于加拿大的美国神经生物学家） 和TorstenWiesel，以及 Roger Sperry。前两位的主要贡献，是“发现了视觉系统的信息处理”，可视皮层是分级的。
人类的视觉原理如下：从原始信号摄入开始（瞳孔摄入像素 Pixels），接着做初步处理（大脑皮层某些细胞发现边缘和方向），然后抽象（大脑判定，眼前的物体的形状，是圆形的），然后进一步抽象（大脑进一步判定该物体是只气球）。下面是人脑进行人脸识别的一个示例：
对于不同的物体，人类视觉也是通过这样逐层分级，来进行认知的：
我们可以看到，在最底层特征基本上是类似的，就是各种边缘，越往上，越能提取出此类物体的一些特征（轮子、眼睛、躯干等），到最上层，不同的高级特征最终组合成相应的图像，从而能够让人类准确的区分不同的物体。
那么我们可以很自然的想到：可以不可以模仿人类大脑的这个特点，构造多层的神经网络，较低层的识别初级的图像特征，若干底层特征组成更上一层特征，最终通过多个层级的组合，最终在顶层做出分类呢？
答案是肯定的，这也是许多深度学习算法（包括CNN）的灵感来源。
2. 卷积神经网络-CNN 的基本原理 典型的 CNN 由3个部分构成：
 卷积层 池化层 全连接层  如果简单来描述的话：卷积层负责提取图像中的局部特征；池化层用来大幅降低参数量级(降维)；全连接层类似传统神经网络的部分，用来输出想要的结果。
下面的原理解释为了通俗易懂，忽略了很多技术细节，如果大家对详细的原理感兴趣，可以看这个视频《卷积神经网络基础 》。
2.1 卷积——提取特征 卷积层的运算过程如下图，用一个卷积核扫完整张图片：
这个过程我们可以理解为我们使用一个过滤器（卷积核）来过滤图像的各个小区域，从而得到这些小区域的特征值。
在具体应用中，往往有多个卷积核，可以认为，每个卷积核代表了一种图像模式，如果某个图像块与此卷积核卷积出的值大，则认为此图像块十分接近于此卷积核。如果我们设计了6个卷积核，可以理解：我们认为这个图像上有6种底层纹理模式，也就是我们用6中基础模式就能描绘出一副图像。以下就是25种不同的卷积核的示例：</description>
    </item>
    
    <item>
      <title>反向传播</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/ai/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%ADbp/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/ai/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%ADbp/</guid>
      <description>说到神经网络，大家看到这个图应该不陌生：
这是典型的三层神经网络的基本构成，Layer L1是输入层，Layer L2是隐含层，Layer L3是隐含层，我们现在手里有一堆数据{x1,x2,x3,&amp;hellip;,xn},输出也是一堆数据{y1,y2,y3,&amp;hellip;,yn},现在要他们在隐含层做某种变换，让你把数据灌进去后得到你期望的输出。如果你希望你的输出和原始输入一样，那么就是最常见的自编码模型（Auto-Encoder）。可能有人会问，为什么要输入输出都一样呢？有什么用啊？其实应用挺广的，在图像识别，文本分类等等都会用到，我会专门再写一篇Auto-Encoder的文章来说明，包括一些变种之类的。如果你的输出和原始输入不一样，那么就是很常见的人工神经网络了，相当于让原始数据通过一个映射来得到我们想要的输出数据，也就是我们今天要讲的话题。
本文直接举一个例子，带入数值演示反向传播法的过程，公式的推导等到下次写Auto-Encoder的时候再写，其实也很简单，感兴趣的同学可以自己推导下试试：）（注：本文假设你已经懂得基本的神经网络构成，如果完全不懂，可以参考Poll写的笔记：[Mechine Learning &amp;amp; Algorithm] 神经网络基础 ）
假设，你有这样一个网络层：
第一层是输入层，包含两个神经元i1，i2，和截距项b1；第二层是隐含层，包含两个神经元h1,h2和截距项b2，第三层是输出o1,o2，每条线上标的wi是层与层之间连接的权重，激活函数我们默认为sigmoid函数。
现在对他们赋上初值，如下图：
其中，输入数据 i1=0.05，i2=0.10;
　输出数据 o1=0.01,o2=0.99;
　初始权重 w1=0.15,w2=0.20,w3=0.25,w4=0.30;
　w5=0.40,w6=0.45,w7=0.50,w8=0.55
目标：给出输入数据i1,i2(0.05和0.10)，使输出尽可能与原始输出o1,o2(0.01和0.99)接近。
Step 1 前向传播
1.输入层&amp;mdash;-&amp;gt;隐含层：
计算神经元h1的输入加权和： $$ \begin{array}{l} n e t_{h 1}=w_{1} * i_{1}+w_{2} * i_{2}+b_{1} * 1 \
{ net }_{h 1}=0.15 * 0.05+0.2 * 0.1+0.35 * 1=0.3775 \end{array} $$ 神经元h1的输出o1:(此处用到激活函数为sigmoid函数)： $$ { out }_{h 1}=\frac{1}{1+e^{-n e t_{h 1}}}=\frac{1}{1+e^{-0.3775}}=0.593269992 $$ 同理，可计算出神经元h2的输出o2： $$ { out }_{h 2}=0.</description>
    </item>
    
    <item>
      <title>常用的模型评估指标</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/ai/%E5%B8%B8%E7%94%A8%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/ai/%E5%B8%B8%E7%94%A8%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</guid>
      <description>“没有测量，就没有科学。”这是科学家门捷列夫的名言。在计算机科学中，特别是在机器学习的领域，对模型的测量和评估同样至关重要。只有选择与问题相匹配的评估方法，我们才能够快速的发现在模型选择和训练过程中可能出现的问题，迭代地对模型进行优化。本文将总结机器学习最常见的模型评估指标，其中包括：
 precision recall F1-score PRC ROC和AUC IOU  从混淆矩阵谈起 看一看下面这个例子：假定瓜农拉来一车西瓜，我们用训练好的模型对这些西瓜进行判别，显然我们可以使用错误率来衡量有多少比例的瓜被判别错误。但如果我们关心的是“挑出的西瓜中有多少比例是好瓜”，或者“所有好瓜中有多少比例被挑出来了”，那么错误率显然就不够用了，这时我们需要引入新的评估指标，比如“查准率”和查全率更适合此类需求的性能度量。
在引入查全率和查准率之前我们必须先理解到什么是混淆矩阵（Confusion matrix）。这个名字起得是真的好，初学者很容易被这个矩阵搞得晕头转向。下图a就是有名的混淆矩阵，而下图b则是由混淆矩阵推出的一些有名的评估指标。
我们首先好好解读一下混淆矩阵里的一些名词和其意思。根据混淆矩阵我们可以得到TP,FN,FP,TN四个值，显然TP+FP+TN+FN=样本总数。这四个值中都带两个字母，单纯记忆这四种情况很难记得牢，我们可以这样理解：第一个字母表示本次预测的正确性，T就是正确，F就是错误；第二个字母则表示由分类器预测的类别，P代表预测为正例，N代表预测为反例。比如TP我们就可以理解为分类器预测为正例（P），而且这次预测是对的（T），FN可以理解为分类器的预测是反例（N），而且这次预测是错误的（F），正确结果是正例，即一个正样本被错误预测为负样本。我们使用以上的理解方式来记住TP、FP、TN、FN的意思应该就不再困难了。，下面对混淆矩阵的四个值进行总结性讲解：
 True Positive （真正，TP）被模型预测为正的正样本 True Negative（真负 , TN）被模型预测为负的负样本 False Positive （假正, FP）被模型预测为正的负样本 False Negative（假负 , FN）被模型预测为负的正样本  Precision、Recall、PRC、F1-score Precision指标在中文里可以称为查准率或者是精确率，Recall指标在中卫里常被称为查全率或者是召回率，查准率 P和查全率 R分别定义为：
查准率P和查全率R的具体含义如下：
  查准率(Precision）是指在所有系统判定的“真”的样本中，确实是真的的占比
  查全率（Recall）是指在所有确实为真的样本中，被判为的“真”的占比
  这里想强调一点，precision和accuracy（正确率）不一样的，accuracy针对所有样本，precision针对部分样本，即正确的预测/总的正反例：
查准率和查全率是一对矛盾的度量，一般而言，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。我们从直观理解确实如此：我们如果希望好瓜尽可能多地选出来，则可以通过增加选瓜的数量来实现，如果将所有瓜都选上了，那么所有好瓜也必然被选上，但是这样查准率就会越低；若希望选出的瓜中好瓜的比例尽可能高，则只选最有把握的瓜，但这样难免会漏掉不少好瓜，导致查全率较低。通常只有在一些简单任务中，才可能使查全率和查准率都很高。
再说PRC， 其全称就是Precision Recall Curve，它以查准率为Y轴，、查全率为X轴做的图。它是综合评价整体结果的评估指标。所以，哪种类型（正或者负）样本多，权重就大。也就是通常说的『对样本不均衡敏感』，『容易被多的样品带走』。
上图就是一幅P-R图，它能直观地显示出学习器在样本总体上的查全率和查准率，显然它是一条总体趋势是递减的曲线。在进行比较时，若一个学习器的PR曲线被另一个学习器的曲线完全包住，则可断言后者的性能优于前者，比如上图中A优于C。但是B和A谁更好呢？因为AB两条曲线交叉了，所以很难比较，这时比较合理的判据就是比较PR曲线下的面积，该指标在一定程度上表征了学习器在查准率和查全率上取得相对“双高”的比例。因为这个值不容易估算，所以人们引入“平衡点”(BEP)来度量，他表示“查准率=查全率”时的取值，值越大表明分类器性能越好，以此比较我们一下子就能判断A较B好。
BEP还是有点简化了，更常用的是F1度量：
F1-score 就是一个综合考虑precision和recall的指标，比BEP更为常用。
ROC &amp;amp; AUC ROC全称是“受试者工作特征”（Receiver Operating Characteristic）曲线，ROC曲线以“真正例率”（TPR）为Y轴，以“假正例率”（FPR）为X轴，对角线对应于“随机猜测”模型，而（0,1）则对应“理想模型”。ROC形式如下图所示。
TPR和FPR的定义如下：
从形式上看TPR就是我们上面提到的查全率Recall，而FPR的含义就是：所有确实为“假”的样本中，被误判真的样本。
进行学习器比较时，与PR图相似，若一个学习器的ROC曲线被另一个学习器的曲线包住，那么我们可以断言后者性能优于前者；若两个学习器的ROC曲线发生交叉，则难以一般性断言两者孰优孰劣。此时若要进行比较，那么可以比较ROC曲线下的面积，即AUC，面积大的曲线对应的分类器性能更好。
AUC（Area Under Curve）的值为ROC曲线下面的面积，若分类器的性能极好，则AUC为1。但现实生活中尤其是工业界不会有如此完美的模型，一般AUC均在0.5到1之间，AUC越高，模型的区分能力越好，上图AUC为0.81。若AUC=0.5，即与上图中红线重合，表示模型的区分能力与随机猜测没有差别。若AUC真的小于0.5，请检查一下是不是好坏标签标反了，或者是模型真的很差。
怎么选择评估指标？ 这种问题的答案当然是具体问题具体分析啦，单纯地回答谁好谁坏是没有意义的，我们需要结合实际场景给出合适的回答。
考虑下面是两个场景，由此看出不同场景下我们关注的点是不一样的：
 对于地震的预测，我们希望的是Recall非常高，也就是说每次地震我们都希望预测出来。这个时候我们可以牺牲Precision。情愿发出1000次警报，把10次地震都预测正确了；也不要预测100次对了8次漏了两次。所以我们可以设定在合理的precision下，最高的recall作为最优点，找到这个对应的threshold点。 嫌疑人定罪基于不错怪一个好人的原则，对于嫌疑人的定罪我们希望是非常准确的。即使有时候放过了一些罪犯（Recall低），但也是值得的。  ROC和PRC在模型性能评估上效果都差不多，但需要注意的是，在正负样本分布得极不均匀(highly skewed datasets)的情况下，PRC比ROC能更有效地反应分类器的好坏。在数据极度不平衡的情况下，譬如说1万封邮件中只有1封垃圾邮件，那么如果我挑出10封，50封，100&amp;hellip;封垃圾邮件（假设我们每次挑出的N封邮件中都包含真正的那封垃圾邮件），Recall都是100%，但是FPR分别是9/9999, 49/9999, 99/9999（数据都比较好看：FPR越低越好），而Precision却只有1/10，1/50， 1/100 （数据很差：Precision越高越好）。所以在数据非常不均衡的情况下，看ROC的AUC可能是看不出太多好坏的，而PR curve就要敏感的多。</description>
    </item>
    
  </channel>
</rss>
