<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>编程思想 on 🇨🇳🇨🇳🇨🇳🇨🇳🇨🇳</title>
    <link>https://xuzhijvn.github.io/zh-cn/categories/%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/</link>
    <description>Recent content in 编程思想 on 🇨🇳🇨🇳🇨🇳🇨🇳🇨🇳</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2016-{year} Razon Yang. All Rights Reserved.</copyright>
    <lastBuildDate>Tue, 01 Mar 2022 16:26:31 +0800</lastBuildDate><atom:link href="https://xuzhijvn.github.io/zh-cn/categories/%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>JVM类的卸载</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm%E7%B1%BB%E7%9A%84%E5%8D%B8%E8%BD%BD/</link>
      <pubDate>Tue, 01 Mar 2022 16:26:31 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm%E7%B1%BB%E7%9A%84%E5%8D%B8%E8%BD%BD/</guid>
      <description>&lt;p&gt;类的卸载：由JVM自带的类加载器所加载的类，在JVM的生命周期中，始终不会被卸载。JVM本身会始终引用这些类加载器，而这些类加载器始终引用它们所加载的类的Class对象。所以说，这些Class对象始终是可触及的。&lt;/p&gt;
&lt;p&gt;由用户自定义的类加载器所加载的类是可以被卸载的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Like查询优化</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/like%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/</link>
      <pubDate>Wed, 16 Feb 2022 10:04:31 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/like%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/</guid>
      <description>&lt;p&gt;本文总结了左前缀匹配（ &lt;code&gt;LIKE &#39;张三%&#39;&lt;/code&gt;）、右后缀匹配（ &lt;code&gt;LIKE &#39;%张三&#39;&lt;/code&gt;）和模糊查询（ &lt;code&gt;LIKE &#39;%张三%&#39;&lt;/code&gt;）常用优化方式。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Redis队列</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/redis/redis%E9%98%9F%E5%88%97/</link>
      <pubDate>Sat, 05 Feb 2022 11:46:49 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/redis/redis%E9%98%9F%E5%88%97/</guid>
      <description>&lt;p&gt;本文深入分析了Redis用作MQ的可行性，对比分析了List、Pub/Sub、Stream的优缺点，并将Stream和专业MQ进行对比分析。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MQ实现延时消息</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mq/mq%E5%AE%9E%E7%8E%B0%E5%BB%B6%E6%97%B6%E6%B6%88%E6%81%AF/</link>
      <pubDate>Thu, 20 Jan 2022 13:58:34 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mq/mq%E5%AE%9E%E7%8E%B0%E5%BB%B6%E6%97%B6%E6%B6%88%E6%81%AF/</guid>
      <description>&lt;p&gt;本文分析一下目前比较主流的几款开源消息中间件对延时消息的支持情况以及实现方式。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>RabbitMQ清空队列的几种方式</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mq/rabbitmq/rabbitmq%E6%B8%85%E7%A9%BA%E9%98%9F%E5%88%97%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Tue, 04 Jan 2022 10:04:18 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mq/rabbitmq/rabbitmq%E6%B8%85%E7%A9%BA%E9%98%9F%E5%88%97%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</guid>
      <description>&lt;p&gt;🔢 🔢&lt;/p&gt;
&lt;p&gt;这里列举几种清空RabbitMQ队列的方案&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Java SPI</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/java-spi/</link>
      <pubDate>Wed, 22 Dec 2021 16:49:52 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/java-spi/</guid>
      <description>&lt;p&gt;本文不回答SPI是什么？而是结合源码深入剖析SPI该怎么使用。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Log4j2 JNDI远程注入漏洞引发的思考</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/log4j2-jndi%E8%BF%9C%E7%A8%8B%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E%E5%BC%95%E5%8F%91%E7%9A%84%E6%80%9D%E8%80%83/</link>
      <pubDate>Sun, 19 Dec 2021 22:55:54 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/log4j2-jndi%E8%BF%9C%E7%A8%8B%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E%E5%BC%95%E5%8F%91%E7%9A%84%E6%80%9D%E8%80%83/</guid>
      <description>&lt;p&gt;12月10日凌晨，Apache 开源项目 Log4j 的远程代码执行漏洞细节被公开，由于其利用简单、危害巨大，一时引起不小的热度。本文将以该事件为切入点，浅析其中涉及的一些技术点。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>JVM OOM</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm-oom/</link>
      <pubDate>Sun, 05 Dec 2021 11:48:50 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm-oom/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TopK</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/topk/</link>
      <pubDate>Sat, 09 Oct 2021 14:38:30 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/topk/</guid>
      <description>public static int topK(int[] arr, int k) {  if (arr == null || k &amp;gt; arr.length || arr.length == 0 || k &amp;lt;= 0) {  return -1;  }  PriorityQueue&amp;lt;Integer&amp;gt; queue = new PriorityQueue&amp;lt;&amp;gt;(k, Comparator.reverseOrder());  for (int i = 0; i &amp;lt; k; i++) {  queue.add(arr[i]);  }  for (int i = k; i &amp;lt; arr.length; i++) {  if (queue.peek() &amp;gt; arr[i]) {  queue.</description>
    </item>
    
    <item>
      <title>数组转树</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/%E6%95%B0%E7%BB%84%E8%BD%AC%E6%A0%91/</link>
      <pubDate>Sat, 09 Oct 2021 14:38:30 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/%E6%95%B0%E7%BB%84%E8%BD%AC%E6%A0%91/</guid>
      <description>private TreeNode buildTree(Integer[] array, int index) {  TreeNode treeNode;  if (index &amp;lt; array.length) {  Integer value = array[index];  if (value == null) {  return null;  }  treeNode = new TreeNode(value);  treeNode.left = buildTree(array, 2 * index + 1);  treeNode.right = buildTree(array, 2 * index + 2);  return treeNode;  }  return null; } </description>
    </item>
    
    <item>
      <title>LRUCache</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/lrucache/</link>
      <pubDate>Sat, 09 Oct 2021 14:24:56 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/lrucache/</guid>
      <description>public class LRUCache&amp;lt;K,V&amp;gt;{   private final int cap;  private final Map&amp;lt;K,V&amp;gt; map;  private final LinkedList&amp;lt;K&amp;gt; list;   public LRUCache(int cap) {  this.cap = cap;  map = new HashMap&amp;lt;&amp;gt;(cap);  list = new LinkedList&amp;lt;&amp;gt;();  }   public void put(K key, V value) {  if (map.size() == cap){  K first = list.removeFirst();  map.remove(first);  }  list.addLast(key);  map.put(key, value);  }   public V get(K key) {  V value = map.</description>
    </item>
    
    <item>
      <title>Redis事务</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/redis/redis%E4%BA%8B%E5%8A%A1/</link>
      <pubDate>Fri, 08 Oct 2021 16:45:53 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/redis/redis%E4%BA%8B%E5%8A%A1/</guid>
      <description>redis它只是做到了：
 它认为的原子性。（单个命令原子，多条命令不一定原子） 隔离性。（单线程执行，各事务串行执行，天然满足隔离） AOF/RDB保证了部分的持久性。（持久化的时候可能存在数据丢失） 它不存在ACID中的C的概念，因为它没有约束。  1. 命令使用错误 这种错误redis在执行前就能检查出来，因此整个事务都不执行。
127.0.0.1:6379&amp;gt; get name &amp;#34;xumeili&amp;#34; 127.0.0.1:6379&amp;gt; get age &amp;#34;28&amp;#34; 127.0.0.1:6379&amp;gt; get sex &amp;#34;female&amp;#34; 127.0.0.1:6379&amp;gt; multi OK 127.0.0.1:6379&amp;gt; set name xuzhijun QUEUED 127.0.0.1:6379&amp;gt; set age (error) ERR wrong number of arguments for &amp;#39;set&amp;#39; command 127.0.0.1:6379&amp;gt; set sex male QUEUED 127.0.0.1:6379&amp;gt; exec (error) EXECABORT Transaction discarded because of previous errors. 127.0.0.1:6379&amp;gt; get name &amp;#34;xumeili&amp;#34; 127.0.0.1:6379&amp;gt; get age &amp;#34;28&amp;#34; 127.0.0.1:6379&amp;gt; get sex &amp;#34;female&amp;#34; 2. 命令执行错误 这种错误redis无法在执行前发现，因此不影响这种错误的前后命令被提交。</description>
    </item>
    
    <item>
      <title>Java序列化</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%BA%8F%E5%88%97%E5%8C%96/</link>
      <pubDate>Mon, 27 Sep 2021 11:24:13 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%BA%8F%E5%88%97%E5%8C%96/</guid>
      <description>&lt;ol&gt;
&lt;li&gt;对象的类名、实例变量（包括基本类型，数组，对其他对象的引用）都会被序列化；方法、类变量、transient实例变量都不会被序列化；&lt;/li&gt;
&lt;li&gt;Serializable反序列化不会调用构造方法；&lt;/li&gt;
&lt;li&gt;单例类序列化，需要重写readResolve()方法；否则会破坏单例原则；&lt;/li&gt;
&lt;li&gt;序列化对象的&lt;code&gt;引用类型变量&lt;/code&gt;也要实现Serializable接口；&lt;/li&gt;
&lt;li&gt;同一对象序列化多次，只有第一次序列化为二进制流，以后都只是保存序列化编号，不会重复序列化；&lt;/li&gt;
&lt;li&gt;使用Externalizable需要实现它的接口，并提供无参构造方法。&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>几种序列化框架对比</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E5%87%A0%E7%A7%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%A1%86%E6%9E%B6%E5%AF%B9%E6%AF%94/</link>
      <pubDate>Sun, 26 Sep 2021 19:49:15 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E5%87%A0%E7%A7%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%A1%86%E6%9E%B6%E5%AF%B9%E6%AF%94/</guid>
      <description>&lt;p&gt;&lt;code&gt;JDK Serializable&lt;/code&gt;, &lt;code&gt;FST&lt;/code&gt; 只适用于Java；&lt;code&gt;Protobuf&lt;/code&gt;, &lt;code&gt;Thrift&lt;/code&gt;, &lt;code&gt;Avro&lt;/code&gt; 支持多种语言，但都需要先通过IDL（接口描述语言，Interface description language）定义Schema；&lt;code&gt;Avro&lt;/code&gt;和&lt;code&gt;Kryo&lt;/code&gt;序列化后的数据最小，&lt;code&gt;FST&lt;/code&gt;和&lt;code&gt;Kryo&lt;/code&gt;序列化时间开销表现最好；&lt;code&gt;Hessian&lt;/code&gt;支持多语言，无需IDL定义Schema，对Java数据类型、语法的支持最佳。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MySQL实验</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/mysql%E5%AE%9E%E9%AA%8C/</link>
      <pubDate>Wed, 22 Sep 2021 14:10:51 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/mysql%E5%AE%9E%E9%AA%8C/</guid>
      <description>&lt;p&gt;实验前提：MySQL默认隔离级别 = &lt;code&gt;REPEATABLE-READ&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Reactive Streams</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/reactive-streams/</link>
      <pubDate>Thu, 16 Sep 2021 17:11:30 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/reactive-streams/</guid>
      <description>&lt;p&gt;JDK的异步处理，一直相对较弱，这方面也有很强的第三方框架。最近在学习这方面的内容，将学习过程记录在这里。&lt;/p&gt;
&lt;p&gt;这篇文章里，主要了解Java中异步流处理的顶级概念：Reactive Streams。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Project Reactor</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/project-reactor/</link>
      <pubDate>Thu, 16 Sep 2021 16:43:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/project-reactor/</guid>
      <description>&lt;p&gt;上一篇文章中，我们介绍了Reactive Streams规范，现在学习一个Reactive Streams规范的流行实现：&lt;code&gt;Project Reactor&lt;/code&gt;的核心项目&lt;code&gt;Reactor Core&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>跨域</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/other/%E8%B7%A8%E5%9F%9F/</link>
      <pubDate>Tue, 14 Sep 2021 15:03:33 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/other/%E8%B7%A8%E5%9F%9F/</guid>
      <description>&lt;p&gt;出于安全考虑，浏览器对跨域请求作出限制，最开始只对访问Cookie做出限制。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>volatile</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/volatile/</link>
      <pubDate>Mon, 13 Sep 2021 15:37:40 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/volatile/</guid>
      <description>&lt;p&gt;JVM volatile用于保证程序&lt;code&gt;可见性&lt;/code&gt;、&lt;code&gt;顺序性&lt;/code&gt;，但是不保证&lt;code&gt;原子性&lt;/code&gt;。volatile实现原理是通过在操作变量之前，多加一个&lt;code&gt;lock前缀指令&lt;/code&gt;，通过汇编可以看到这个前缀指令。&lt;/p&gt;
&lt;p&gt;当谈到顺序性时常会提到&lt;code&gt;内存屏障&lt;/code&gt;，常见的硬件层面&lt;code&gt;内存屏障&lt;/code&gt;有：&lt;code&gt;sfence&lt;/code&gt;    &lt;code&gt;lfence&lt;/code&gt;     &lt;code&gt;mfence&lt;/code&gt; ，&lt;code&gt;lock前缀指令&lt;/code&gt;不是内存屏障，而是一种锁，执行时会锁住内存子系统来确保执行顺序，甚至跨多个CPU，JVM利用lock前缀指令的特点实现了&lt;code&gt;可见性&lt;/code&gt; 和 &lt;code&gt;顺序性&lt;/code&gt;，lock前缀指令实现可见性比较好理解，主要是利用CPU提供的缓存一致性协议（例如Intel的MESI）,当然更差一点的还有lock总线的方式（限制CPU访问内存）。&lt;/p&gt;
&lt;p&gt;JMM层面为了实现&lt;code&gt;顺序性&lt;/code&gt;，又抽象出四个&lt;code&gt;内存屏障&lt;/code&gt;的概念：&lt;code&gt;LoadLoad&lt;/code&gt;     &lt;code&gt;StoreStore&lt;/code&gt;    &lt;code&gt;LoadStore&lt;/code&gt;    &lt;code&gt;StoreLoad&lt;/code&gt;，字节码层面并没有&lt;code&gt;内存屏障&lt;/code&gt;的指令，JVM的C++代码会有四个同名函数与之对应，JVM遇到volatile变量便会在其前后执行对应的函数，从而实现内存屏障，具体来说：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;LoadLoadBarrier
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;volatile&lt;/span&gt; 读操作
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;LoadStoreBarrier
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;StoreStoreBarrier
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;volatile&lt;/span&gt; 写操作
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;StoreLoadBarrie
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>JVM锁优化</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm%E9%94%81%E4%BC%98%E5%8C%96/</link>
      <pubDate>Thu, 09 Sep 2021 10:46:14 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm%E9%94%81%E4%BC%98%E5%8C%96/</guid>
      <description></description>
    </item>
    
    <item>
      <title>JVM内存模型</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Mon, 06 Sep 2021 00:13:21 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</guid>
      <description></description>
    </item>
    
    <item>
      <title>JVM类加载器</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8/</link>
      <pubDate>Mon, 06 Sep 2021 00:13:02 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8/</guid>
      <description></description>
    </item>
    
    <item>
      <title>JVM架构</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm%E6%9E%B6%E6%9E%84/</link>
      <pubDate>Mon, 06 Sep 2021 00:10:01 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm%E6%9E%B6%E6%9E%84/</guid>
      <description></description>
    </item>
    
    <item>
      <title>JVM垃圾回收</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</link>
      <pubDate>Sun, 05 Sep 2021 23:48:46 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</guid>
      <description></description>
    </item>
    
    <item>
      <title>String常量池</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/string%E5%B8%B8%E9%87%8F%E6%B1%A0/</link>
      <pubDate>Sun, 05 Sep 2021 11:54:01 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/string%E5%B8%B8%E9%87%8F%E6%B1%A0/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SpringAOP执行顺序</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/spring/springaop%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F/</link>
      <pubDate>Tue, 31 Aug 2021 14:50:56 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/spring/springaop%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MyBatis缓存机制</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mybatis/mybatis%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Mon, 30 Aug 2021 21:16:45 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mybatis/mybatis%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/</guid>
      <description></description>
    </item>
    
    <item>
      <title>基于keepalived实现nginx高可用</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/nginx/%E5%9F%BA%E4%BA%8Ekeepalived%E5%AE%9E%E7%8E%B0nginx%E9%AB%98%E5%8F%AF%E7%94%A8/</link>
      <pubDate>Sun, 29 Aug 2021 23:33:21 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/nginx/%E5%9F%BA%E4%BA%8Ekeepalived%E5%AE%9E%E7%8E%B0nginx%E9%AB%98%E5%8F%AF%E7%94%A8/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Nginx负载均衡</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/nginx/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</link>
      <pubDate>Sun, 29 Aug 2021 23:29:12 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/nginx/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>字节码实战</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E5%AD%97%E8%8A%82%E7%A0%81%E5%AE%9E%E6%88%98/</link>
      <pubDate>Sun, 29 Aug 2021 13:28:08 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E5%AD%97%E8%8A%82%E7%A0%81%E5%AE%9E%E6%88%98/</guid>
      <description></description>
    </item>
    
    <item>
      <title>300. 最长递增子序列</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/300.-%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/300.-%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97/</guid>
      <description>class Solution {  public int lengthOfLIS(int[] nums) {  if (nums == null || nums.length == 0){return 0;}  int[] dp = new int[nums.length];  Arrays.fill(dp,1);  for (int i = 0; i &amp;lt; nums.length; i++) {  for (int j = 0; j &amp;lt; i; j++) {  if(nums[i] &amp;gt; nums[j] &amp;amp;&amp;amp; dp[j] + 1 &amp;gt; dp[i]){  dp[i] = dp[j] + 1;  }  }  }  return Arrays.</description>
    </item>
    
    <item>
      <title>400 Bad Request</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/nginx/400-bad-request/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/nginx/400-bad-request/</guid>
      <description>需要设置 proxy_set_header Host $host:$server_port;
location ^~/gateway/ {  proxy_set_header Host $host:$server_port;  proxy_set_header X-Real-IP $remote_addr;  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;  proxy_set_header X-NginX-Proxy true;  proxy_pass http://k8s_yshop-gateway-svc/; } </description>
    </item>
    
    <item>
      <title>AQS</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/aqs/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/aqs/</guid>
      <description>AQS作为Java并发编程的基石，在Java同步工具中有广泛应用，例如：ReentrantLock , Semaphore , CountDownLatch ReentrantReadWriteLock , ThreadPoolExecutor
一般来说，自定义同步器要么是独占方式，要么是共享方式，它们也只需实现 tryAcquire / tryRelease , tryAcquireShared / tryReleaseShared 中的一组即可。AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。ReentrantLock是独占锁。
AQS核心思想是：如果被请求的共享资源（state）空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。
CLH：Craig, Landin, and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。
主要原理图如下：
AQS使用一个Volatile的int类型的成员变量state来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。
获得锁 acquire()是独占模式下线程获取共享资源的顶层入口。如果获取到资源，线程直接返回，否则进入等待队列，直到获取到资源为止，且整个过程忽略中断的影响。获取到资源后，线程就可以去执行其临界区代码了。
public final void acquire(int arg) {  if (!tryAcquire(arg) &amp;amp;&amp;amp;  acquireQueued(addWaiter(Node.EXCLUSIVE), arg))  selfInterrupt(); } 如果再有线程要获取锁，依次在队列中往后排队即可。
tryAcquire()方法尝试去获取独占资源。如果获取成功，则直接返回true，否则直接返回false。需自定义同步器去实现
protected boolean tryAcquire(int arg) {  throw new UnsupportedOperationException(); } AQS只是一个框架，具体资源的获取/释放方式交由自定义同步器去实现吗。AQS这里只定义了一个接口，具体资源的获取交由自定义同步器去实现了（通过state的get/set/CAS）！！！至于能不能重入，能不能加塞，那就看具体的自定义同步器怎么去设计了！！
addWaiter(Node)此方法用于将当前线程加入到等待队列的队尾，并返回当前线程所在的结点。
private Node addWaiter(Node mode) {  //以给定模式构造结点。mode有两种：EXCLUSIVE（独占）和SHARED（共享）  Node node = new Node(Thread.currentThread(), mode);   //尝试快速方式直接放到队尾。  Node pred = tail;  if (pred !</description>
    </item>
    
    <item>
      <title>Async</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/spring/async/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/spring/async/</guid>
      <description>Spring Boot系列二 Spring @Async异步线程池用法总结
springboot利用@Async提升API接口并发能力</description>
    </item>
    
    <item>
      <title>BeanFactoryPostProcessor和BeanPostProcessor</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/spring/beanfactorypostprocessor%E5%92%8Cbeanpostprocessor/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/spring/beanfactorypostprocessor%E5%92%8Cbeanpostprocessor/</guid>
      <description>BeanFactoryPostProcessor工作在Bean实例化之前，BeanPostProcessor工作在Bean初始化方法前后。
BeanFactoryPostProcessor和BeanPostProcessor，这两个接口，都是Spring初始化bean时对外暴露的扩展点。两个接口名称看起来很相似，但作用及使用场景却不同，分析如下：
1. BeanFactoryPostProcessor接口 该接口的定义如下：
@FunctionalInterface public interface BeanFactoryPostProcessor {  	/** * Modify the application context&amp;#39;s internal bean factory after its standard * initialization. All bean definitions will have been loaded, but no beans * will have been instantiated yet. This allows for overriding or adding * properties even to eager-initializing beans. * @param beanFactory the bean factory used by the application context * @throws org.springframework.beans.BeansException in case of errors */ 	void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;  } 实现该接口，可以在spring的bean创建之前，修改bean的定义属性。也就是说，Spring允许BeanFactoryPostProcessor在容器实例化任何其它bean之前读取配置元数据，并可以根据需要进行修改，例如可以把bean的scope从singleton改为prototype，也可以把property的值给修改掉。可以同时配置多个BeanFactoryPostProcessor，并通过设置&amp;rsquo;order&amp;rsquo;属性来控制各个BeanFactoryPostProcessor的执行次序。</description>
    </item>
    
    <item>
      <title>bean生命周期</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/spring/bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/spring/bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</guid>
      <description>实例化 -&amp;gt; 属性赋值 -&amp;gt; 初始化 -&amp;gt; 销毁
参考链接 请别再问Spring Bean的生命周期了！
Spring Bean的生命周期（非常详细）</description>
    </item>
    
    <item>
      <title>char varchar text区别</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/char-varchar-text%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/char-varchar-text%E5%8C%BA%E5%88%AB/</guid>
      <description>参考 MySQL之char、varchar和text的设计</description>
    </item>
    
    <item>
      <title>ClickHouse综述</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/clickhouse/clickhouse%E7%BB%BC%E6%9C%AF/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/clickhouse/clickhouse%E7%BB%BC%E6%9C%AF/</guid>
      <description>列式存储优势   当查询语句只涉及部分列时，只需要扫描相关的列
  每一列的数据都是相同类型的，彼此间相关性更大，对列数据压缩的效率较高
  参考 “行式存储”和“列式存储”的区别
什么是ClickHouse？</description>
    </item>
    
    <item>
      <title>CompletableFuture使用详解</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/completablefuture%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/completablefuture%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3/</guid>
      <description>1. runAsync 和 supplyAsync方法 CompletableFuture 提供了四个静态方法来创建一个异步操作。
public static CompletableFuture&amp;lt;Void&amp;gt; runAsync(Runnable runnable) public static CompletableFuture&amp;lt;Void&amp;gt; runAsync(Runnable runnable, Executor executor) public static &amp;lt;U&amp;gt; CompletableFuture&amp;lt;U&amp;gt; supplyAsync(Supplier&amp;lt;U&amp;gt; supplier) public static &amp;lt;U&amp;gt; CompletableFuture&amp;lt;U&amp;gt; supplyAsync(Supplier&amp;lt;U&amp;gt; supplier, Executor executor) 没有指定Executor的方法会使用ForkJoinPool.commonPool() 作为它的线程池执行异步代码。如果指定线程池，则使用指定的线程池运行。以下所有的方法都类同。
 runAsync方法不支持返回值。 supplyAsync可以支持返回值。  示例 //无返回值 public static void runAsync() throws Exception {  CompletableFuture&amp;lt;Void&amp;gt; future = CompletableFuture.runAsync(() -&amp;gt; {  try {  TimeUnit.SECONDS.sleep(1);  } catch (InterruptedException e) {  }  System.out.println(&amp;#34;run end .</description>
    </item>
    
    <item>
      <title>dockerfile-maven-plugin使用</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/maven/dockerfile-maven-plugin%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/maven/dockerfile-maven-plugin%E4%BD%BF%E7%94%A8/</guid>
      <description>&amp;lt;properties&amp;gt;  &amp;lt;docker.image.prefix&amp;gt;anaham-docker.pkg.coding.net/cereshop/ceres&amp;lt;/docker.image.prefix&amp;gt;  &amp;lt;anaham-docker.username&amp;gt;用户名&amp;lt;/anaham-docker.username&amp;gt;  &amp;lt;anaham-docker.password&amp;gt;密码&amp;lt;/anaham-docker.password&amp;gt; &amp;lt;/properties&amp;gt;  &amp;lt;build&amp;gt;  &amp;lt;plugins&amp;gt;  &amp;lt;plugin&amp;gt;  &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;  &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;  &amp;lt;executions&amp;gt;  &amp;lt;execution&amp;gt;  &amp;lt;goals&amp;gt;  &amp;lt;goal&amp;gt;repackage&amp;lt;/goal&amp;gt;  &amp;lt;/goals&amp;gt;  &amp;lt;/execution&amp;gt;  &amp;lt;/executions&amp;gt;  &amp;lt;/plugin&amp;gt;  &amp;lt;!-- docker打包插件 --&amp;gt;  &amp;lt;plugin&amp;gt;  &amp;lt;groupId&amp;gt;com.spotify&amp;lt;/groupId&amp;gt;  &amp;lt;artifactId&amp;gt;dockerfile-maven-plugin&amp;lt;/artifactId&amp;gt;  &amp;lt;version&amp;gt;${dockerfile-maven-plugin.version}&amp;lt;/version&amp;gt;  &amp;lt;configuration&amp;gt;  &amp;lt;username&amp;gt;${anaham-docker.username}&amp;lt;/username&amp;gt;  &amp;lt;password&amp;gt;${anaham-docker.password}&amp;lt;/password&amp;gt;  &amp;lt;repository&amp;gt;${docker.image.prefix}/${project.artifactId}&amp;lt;/repository&amp;gt;  &amp;lt;tag&amp;gt;${ceres.version}&amp;lt;/tag&amp;gt; &amp;lt;!-- 不指定tag默认为latest --&amp;gt;  &amp;lt;buildArgs&amp;gt;  &amp;lt;JAR_FILE&amp;gt;target/${project.build.finalName}.jar&amp;lt;/JAR_FILE&amp;gt;  &amp;lt;/buildArgs&amp;gt;  &amp;lt;/configuration&amp;gt;  &amp;lt;/plugin&amp;gt;  &amp;lt;/plugins&amp;gt; &amp;lt;/build&amp;gt;  构建镜像  mvn clean package -Dmaven.</description>
    </item>
    
    <item>
      <title>ES综述</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/es/es%E7%BB%BC%E8%BF%B0/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/es/es%E7%BB%BC%E8%BF%B0/</guid>
      <description>1. ES 的分布式架构原理 ElasticSearch 设计的理念就是分布式搜索引擎，底层其实还是基于 lucene 的。核心思想就是在多台机器上启动多个 ES 进程实例，组成了一个 ES 集群。
默认节点会去加入一个名称为 elasticsearch 的集群。如果直接启动一堆节点，那么它们会自动组成一个 elasticsearch 集群，当然一个节点也可以组成 elasticsearch 集群。
1.1 ES数据结构 ES 中存储数据的基本单位是索引，比如说你现在要在 ES 中存储一些订单数据，你就应该在 ES 中创建一个索引 order_idx ，所有的订单数据就都写到这个索引里面去，一个索引差不多就是相当于是 mysql 里的一张表。
index -&amp;gt; type -&amp;gt; mapping -&amp;gt; document -&amp;gt; field。 1.2 ES高可用 类似kafka将一个topic分成多个partition，es将一个index分成多个shard。
 每个 shard 存储部分数据。拆分多个 shard 是有好处的，一是支持横向扩展，比如你数据量是 3T，3 个 shard，每个 shard 就 1T 的数据，若现在数据量增加到 4T，怎么扩展，很简单，重新建一个有 4 个 shard 的索引，将数据导进去；二是提高性能，数据分布在多个 shard，即多台服务器上，所有的操作，都会在多台机器上并行分布式执行，提高了吞吐量和性能。
 kafka的每个partition有多个replica副本，所有副本选出一个leader（依赖zookeeper完成选举）负责所有的读写请求。
ES 的每个shard也可以配置多个replica副本，每个 shard 都有一个 primary shard ，负责写入数据，但是还有几个 replica shard 。 primary shard 写入数据之后，会将数据同步到其他几个 replica shard 上去。</description>
    </item>
    
    <item>
      <title>GitHub 443</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/git/github-443/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/git/github-443/</guid>
      <description>我们真是一个神奇的国度，连github都要封禁。
最近github https无法接入：
fatal: unable to access &amp;#39;https://github.com/xuzhijvn/tony-demo.git/&amp;#39;: LibreSSL SSL_connect: SSL_ERROR_SYSCALL in connection to github.com:443 试了n种方式都不行：
  切换SSR代理节点
  切换SSR代理模式到全局
  退出SSR
  使用蓝灯代理
  设置git代理（61885是我蓝灯代理的端口）
  git config --global --list  git config --global https.proxy &amp;#39;127.0.0.1:61885&amp;#39; git config --global http.proxy &amp;#39;127.0.0.1:61885&amp;#39;  git config --global --list 禁用git代理  git config --global --list  git config --global --unset http.proxy  git config --global --list networksetup -setv6off Wi-Fi  以上方法全部不好使，折腾了一下午心态崩了💔💔</description>
    </item>
    
    <item>
      <title>Golang的协程调度器原理及GMP设计思想</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/go/golang%E7%9A%84%E5%8D%8F%E7%A8%8B%E8%B0%83%E5%BA%A6%E5%99%A8%E5%8E%9F%E7%90%86%E5%8F%8Agmp%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/go/golang%E7%9A%84%E5%8D%8F%E7%A8%8B%E8%B0%83%E5%BA%A6%E5%99%A8%E5%8E%9F%E7%90%86%E5%8F%8Agmp%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/</guid>
      <description>多线程为我们的程序提供了强大的并发能力，但是随着现代应用对并发能力越来越高的要求，仍然通过增加线程数量提升并发能力的做法显然无法维系，因为创建线程要消耗内存，更致命的是众多的线程创建、销毁、切换将大大降低CPU的执行效率。
如何通过有限的线程数量进一步提升应用的并发能力呢？协程、线程池都是解决之道。
协程可以看作是用户态的线程，因此协程间的切换并不会有CPU的损耗，并且可以将每个协程设计成几kb大小，以至于可以创建大量的协程。CPU最终调度运行仍然是线程，因此协程与线程之间需要一个 调度器，Golang中有GMP调度器，用于把大量的协程分配到少量线程上去执行。
 本节为重点章节 本章节含视频版:
 
 一、Golang“调度器”的由来？ (1) 单进程时代不需要调度器 我们知道，一切的软件都是跑在操作系统上，真正用来干活(计算)的是CPU。早期的操作系统每个程序就是一个进程，直到一个程序运行完，才能进行下一个进程，就是“单进程时代”
一切的程序只能串行发生。
早期的单进程操作系统，面临2个问题：
1.单一的执行流程，计算机只能一个任务一个任务处理。
2.进程阻塞所带来的CPU时间浪费。
那么能不能有多个进程来宏观一起来执行多个任务呢？
后来操作系统就具有了最早的并发能力：多进程并发，当一个进程阻塞的时候，切换到另外等待执行的进程，这样就能尽量把CPU利用起来，CPU就不浪费了。
(2)多进程/线程时代有了调度器需求 在多进程/多线程的操作系统中，就解决了阻塞的问题，因为一个进程阻塞cpu可以立刻切换到其他进程中去执行，而且调度cpu的算法可以保证在运行的进程都可以被分配到cpu的运行时间片。这样从宏观来看，似乎多个进程是在同时被运行。
但新的问题就又出现了，进程拥有太多的资源，进程的创建、切换、销毁，都会占用很长的时间，CPU虽然利用起来了，但如果进程过多，CPU有很大的一部分都被用来进行进程调度了。
怎么才能提高CPU的利用率呢？
但是对于Linux操作系统来讲，cpu对进程的态度和线程的态度是一样的。
很明显，CPU调度切换的是进程和线程。尽管线程看起来很美好，但实际上多线程开发设计会变得更加复杂，要考虑很多同步竞争等问题，如锁、竞争冲突等。
(3)协程来提高CPU利用率 多进程、多线程已经提高了系统的并发能力，但是在当今互联网高并发场景下，为每个任务都创建一个线程是不现实的，因为会消耗大量的内存(进程虚拟内存会占用4GB[32位操作系统], 而线程也要大约4MB)。
大量的进程/线程出现了新的问题
 高内存占用 调度的高消耗CPU  好了，然后工程师们就发现，其实一个线程分为“内核态“线程和”用户态“线程。
一个“用户态线程”必须要绑定一个“内核态线程”，但是CPU并不知道有“用户态线程”的存在，它只知道它运行的是一个“内核态线程”(Linux的PCB进程控制块)。
这样，我们再去细化去分类一下，内核线程依然叫“线程(thread)”，用户线程叫“协程(co-routine)&amp;quot;.
看到这里，我们就要开脑洞了，既然一个协程(co-routine)可以绑定一个线程(thread)，那么能不能多个协程(co-routine)绑定一个或者多个线程(thread)上呢。
之后，我们就看到了有3中协程和线程的映射关系：
 N:1关系  N个协程绑定1个线程，优点就是协程在用户态线程即完成切换，不会陷入到内核态，这种切换非常的轻量快速。但也有很大的缺点，1个进程的所有协程都绑定在1个线程上
缺点：
 某个程序用不了硬件的多核加速能力 一旦某协程阻塞，造成线程阻塞，本进程的其他协程都无法执行了，根本就没有并发的能力了。   1:1 关系  1个协程绑定1个线程，这种最容易实现。协程的调度都由CPU完成了，不存在N:1缺点，
缺点：
 协程的创建、删除和切换的代价都由CPU完成，有点略显昂贵了。   M:N关系  M个协程绑定1个线程，是N:1和1:1类型的结合，克服了以上2种模型的缺点，但实现起来最为复杂。
协程跟线程是有区别的，线程由CPU调度是抢占式的，协程由用户态调度是协作式的，一个协程让出CPU后，才执行下一个协程。
(4)Go语言的协程goroutine Go为了提供更容易使用的并发方法，使用了goroutine和channel。goroutine来自协程的概念，让一组可复用的函数运行在一组线程之上，即使有协程阻塞，该线程的其他协程也可以被runtime调度，转移到其他可运行的线程上。最关键的是，程序员看不到这些底层的细节，这就降低了编程的难度，提供了更容易的并发。
Go中，协程被称为goroutine，它非常轻量，一个goroutine只占几KB，并且这几KB就足够goroutine运行完，这就能在有限的内存空间内支持大量goroutine，支持了更多的并发。虽然一个goroutine的栈只占几KB，但实际是可伸缩的，如果需要更多内容，runtime会自动为goroutine分配。
Goroutine特点：
 占用内存更小（几kb） 调度更灵活(runtime调度)  (5)被废弃的goroutine调度器 好了，既然我们知道了协程和线程的关系，那么最关键的一点就是调度协程的调度器的实现了。</description>
    </item>
    
    <item>
      <title>go多版本切换</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/go/go%E5%A4%9A%E7%89%88%E6%9C%AC%E5%88%87%E6%8D%A2/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/go/go%E5%A4%9A%E7%89%88%E6%9C%AC%E5%88%87%E6%8D%A2/</guid>
      <description>方法一：调整PATH export PATH=/usr/local/go/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin 方法二：调整软链接(未验证) //查看当前软链接指向 cd /usr/local/bin ls -trl | grep go //调整软链接 ln -snf /usr/local/Cellar/go/1.16.3/bin go </description>
    </item>
    
    <item>
      <title>HashMap和HashTable区别</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/hashmap%E5%92%8Chashtable%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/hashmap%E5%92%8Chashtable%E5%8C%BA%E5%88%AB/</guid>
      <description> HashMap是HashTable的轻量级版本， HashTable是线程安全的，其方法都被synchronized关键同步 HashMap 把 Hashtable 的 contains 方法去掉了，改成 containsValue 和 containsKey。因为 contains 方法容易让人引起误解。 HashMap允许将 null 作为一个 entry 的 key 或者 value，而 Hashtable 不允许。 HashTable 继承自 Dictionary 类，而 HashMap 是 Java1.2 引进的 Map interface 的一个实现。 Hashtable 和 HashMap 采用的 hash/rehash 算法都大概一样，所以性能不会有很大的差异。  </description>
    </item>
    
    <item>
      <title>io.lettuce.core.RedisCommandTimeoutException: Command timed out after 5 second(s)</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/exception/io.lettuce.core.rediscommandtimeoutexception_-comm/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/exception/io.lettuce.core.rediscommandtimeoutexception_-comm/</guid>
      <description>lettuce连接redis报错io.lettuce.core.RedisCommandTimeoutException: Command timed out after 5 second(s)，我的spring.redis.timeout = 5000。
解决办法：
 登陆redis容器 输入redis-cli进入redis控制台 设置 CONFIG SET timeout &amp;quot;60&amp;quot; 设置 CONFIG SET tcp-keepalive &amp;quot;300&amp;quot;  参考 Redis 配置</description>
    </item>
    
    <item>
      <title>Java Agent</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/java-agent/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/java-agent/</guid>
      <description>Java Agent就是一个可以作为java代理的工具, 简单来说就是一个可供用于编写的java切面, 它的主要功能就是为用户提供了在 JVM 将字节码文件读入内存之后，JVM 使用对应的字节流在 Java 堆中生成一个 Class 对象之前，用户可以对其字节码进行修改的能力，从而 JVM 也将会使用用户修改过之后的字节码进行新的Class 对象的创建(打破了一个类只能加载一次的规则)。
Java Agent的使用对于你自身的代码是无侵入性的。应用场景：热更新。
热更新我们也可以自定义类加载器实现，这种方式的热更新是jvm原生支持的方式, 但是缺点也很明显:
  不够灵活, 需要手动修改文件等操作
  重复创建类加载器, 并且卸载困难, 会增加系统负担
  使用起来具有代码侵入性, 需要对代码进行一定改造
  通过 Java Agent完美的解决了我们自定义类加载器实现热更新的缺点。
1.1 JVM启动前静态Instrument 通过启动命令 java -javaagent:agent1.jar -javaagent:agent2.jar -jar MyProgram.jar 在目标程序main方法执行前，先执行agent中定义的 premain 方法
1.2 JVM启动后动态Instrument Java6 以后提供了在目标程序main方法执行后，执行agent的agentmain方法的机制，通过这种机制，我们可以动态修改目标程序已经加载过的字节码。
在Java6 以后实现启动后加载的新实现是Attach API 。Attach API 很简单，只有 2 个主要的类，即VirtualMachine 和 VirtualMachineDescriptor，都在tool.jar 的 com.sun.tools.attach 包里面。
attach实现动态注入的原理如下：
通过VirtualMachine类的attach(pid)方法，便可以attach到一个运行中的java进程上，之后便可以通过loadAgent(agentJarPath)来将agent的jar包注入到对应的进程，然后对应的进程会调用agentmain方法。
既然是两个进程之间通信那肯定的建立起连接，VirtualMachine.attach动作类似TCP创建连接的三次握手，目的就是搭建attach通信的连接。而后面执行的操作，例如vm.loadAgent，其实就是向这个socket写入数据流，接收方target VM会针对不同的传入数据来做不同的处理。
例如：找到当前JVM并加载agent.jar（即attach JVM 和 runing JVM 是同一个 JVM，真正的应用中更多的是不同的两个JVM，这里仅为了测试方便。）</description>
    </item>
    
    <item>
      <title>Java switch表达式支持的数据类型</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/java-switch%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/java-switch%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid>
      <description>switch(expression){  case value :  //语句  break; //可选  case value :  //语句  break; //可选  //你可以有任意数量的case语句  default : //可选  //语句 } 这里的 expression 支持：
1、基本数据类型：byte, short, char, int
2、包装数据类型：Byte, Short, Character, Integer
3、枚举类型：Enum
4、 字符串类型：String（Jdk 7+ 开始支持）
为什么不支持long、float、double数据类型？
switch 底层是使用 int 型 来进行判断的，即使是枚举、String类型，最终也是转变成 int 型。由于 long、float、double 型表示范围大于 int 型，因此不支持 long、float、double 类型。 （String类型最终是转成了int类型的hashCode；枚举最终转成了枚举对象的定义顺序，即 ordinal值）
下面举一个使用包装类型和枚举的，其实也不难，注意只能用在 switch 块里面
// 使用包装类型 Integer value = 5; switch (value) {  case 3:  System.</description>
    </item>
    
    <item>
      <title>Java安装指南</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/</guid>
      <description>1. 下载JDK 进入Oracle 官方网站下载合适的 JDK 版本，准备安装。
2. 创建目录 执行如下命令，在 /usr/ 目录下创建 java 目录。
mkdir /usr/java cd /usr/java 将下载的文件 jdk-8u151-linux-x64.tar.gz 复制到 /usr/java/ 目录下。
3. 解压 JDK tar -zxvf jdk-8u151-linux-x64.tar.gz 4. 设置环境变量 set java environment JAVA_HOME=/usr/java/jdk1.8.0_151 JRE_HOME=/usr/java/jdk1.8.0_151/jre CLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin export JAVA_HOME JRE_HOME CLASS_PATH PATH 使修改生效：
source /etc/profile 5. 测试 执行如下命令进行测试。
java -version 若显示 Java 版本信息，则说明 JDK 安装成功：
java version &amp;#34;1.8.0_151&amp;#34; Java(TM) SE Runtime Environment (build 1.8.0_151-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.</description>
    </item>
    
    <item>
      <title>Java堆外内存溢出</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/</guid>
      <description>前段时间在做一个实时人脸抓拍项目的时候，遇到了一个堆外内存OOM的问题，现在把思路好好整理一下。
项目中用opencv通过rtsp协议，实时的读取通用网络摄像头的视频帧。因为项目中多处用到了org.opencv.core.Mat这个对象，而Mat对象的构造是通过调用native方法实现的，也就是说构造Mat对象的时候，会在堆外分配内存：
 //  // C++: Mat::Mat()  //   // javadoc: Mat::Mat()  public Mat()  {   nativeObj = n_Mat();   return;  }  // C++: Mat::Mat()  private static native long n_Mat(); 堆外分配的内存不受JVM的内存管理。由于又没有主动调用Mat.realse()去释放堆外内存，导致堆外内存OOM。
其实解决的办法很简单，可以在Mat对象使用完毕后直接调用Mat.realse()释放堆外内存。（没有试过，本人使用的下面的方式）
但是，Mat对象充斥着整个项目，要跟踪Mat对象的生命周期显得有点复杂，而且因为太多地方使用了Mat对象，很有可能遗漏调用Mat.realse()释放内存。因此，还是想把这部分内存的释放交由JVM来做，具体的方式是：定期的调用System.gc()执行垃圾回收（很多人说System.gc()只是建议JVM执行垃圾回收，并不是命令，是否执行取决去JVM自己，但是，经我实测，每次调用System.gc()都会触发垃圾回收。），JVM在垃圾回收前会执行每个**空java对象（null）**的finalize()方法，而Mat对象的finalize()方法正好实现了释放内存的逻辑：
 @Override  protected void finalize() throws Throwable {  n_delete(nativeObj);  super.finalize();  }  // native support for java finalize()  private static native void n_delete(long nativeObj); 因为会定时的调用System.</description>
    </item>
    
    <item>
      <title>Java对象的hashCode方法</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%AF%B9%E8%B1%A1%E7%9A%84hashcode%E6%96%B9%E6%B3%95/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%AF%B9%E8%B1%A1%E7%9A%84hashcode%E6%96%B9%E6%B3%95/</guid>
      <description>java中的Object类的hashCode方法是一个native方法，查看native源码过于困难，所以暂且认为 Object类的hashCode生成规则是：hash(对象的内存地址+一些其他信息)
java中String类的 hashCode方法 比较直观，源码如下：
 public int hashCode() {  int h = hash;  if (h == 0 &amp;amp;&amp;amp; value.length &amp;gt; 0) {  char val[] = value;   for (int i = 0; i &amp;lt; value.length; i++) {  h = 31 * h + val[i];  }  hash = h;  }  return h;  } 生成规则：s[0]*31^(n-1) + s[1]*31^(n-2) + &amp;hellip; + s[n-1]</description>
    </item>
    
    <item>
      <title>Java反射</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%8F%8D%E5%B0%84/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%8F%8D%E5%B0%84/</guid>
      <description>反射可以在程序运行过程中动态的构造类、获取类的全部信息、调用类型方法。但是，为什么我们要这么做呢？需要构造类，new就好了，需要访问类成员变量、调用方法，直接访问、调用就好了，为什么要通过一大堆反射代码去实现呢？
通常，class在编译期间就确定，JVM在运行时通过类加载器加载确定的class。如果在运行时才确定需要加载什么类，就需要利用java反射。java反射使得程序更加灵活，类似spring的框架将类以全限定名的形成配置在配置文件，然后再通过反射实例化。
参考：
https://blog.csdn.net/Appleyk/article/details/77879073</description>
    </item>
    
    <item>
      <title>Java如何绑定线程到指定CPU上执行</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%A6%82%E4%BD%95%E7%BB%91%E5%AE%9A%E7%BA%BF%E7%A8%8B%E5%88%B0%E6%8C%87%E5%AE%9Acpu%E4%B8%8A%E6%89%A7%E8%A1%8C/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%A6%82%E4%BD%95%E7%BB%91%E5%AE%9A%E7%BA%BF%E7%A8%8B%E5%88%B0%E6%8C%87%E5%AE%9Acpu%E4%B8%8A%E6%89%A7%E8%A1%8C/</guid>
      <description>绑定核心之后不存在线程的上下文切换，就可以更好的利用CPU缓存。
 不知道你是啥感觉，但是我第一次看到这个问题的时候，我是懵逼的。
而且它还是一个面试题。
我懵逼倒不是因为我不知道答案，而是恰好我之前在非常机缘巧合的情况下知道了答案。
我感觉非常的冷门，作为一个考察候选者的知识点出现在面试环节中不太合适，除非是候选者主动提起做过这样的优化。
而且怕就怕面试官也是恰巧在某个书上或者博客中知道这个东西，稍微的看了一下，以为自己学到了绝世武功，然后拿出去考别人。
这样不合适。
说回这个题目。
正常来说，其实应该是属于考察操作系统的知识点范畴。
但是面试官呢又特定的加了“在 Java 中如何实现”。
那我们就聊聊这个问题。
Java线程 在聊如何绑定之前，先铺垫一个相关的背景知识：Java线程的实现。
其实我们都知道 Thread 类的大部分方法都是 native 方法：
在 Java 中一个方法被声明为 native 方法，绝大部分情况下说明这个方法没有或者不能使用平台无关的手段来实现。
说明需要操作的是很底层的东西了，已经脱离了 Java 语言层面的范畴。
抛开 Java 语言这个大前提，实现线程主要是有三种方式：
 1.使用内核线程实现（1:1实现） 2.使用用户线程实现（1:N实现） 3.使用用户线程加轻量级进程混合实现（N:M实现）
 这三种实现方案，在《深入理解Java虚拟机》的 12.4 小节有详细的描述，有兴趣的同学可以去仔细的翻阅一下。
总之，你要知道的是虽然有这三种不同的线程模型，但是 Java 作为上层应用，其实是感知不到这三种模型之间的区别的。
JVM 规范里面也没有规定，必须使用哪一种模型。
因为操作系统支持是怎样的线程模型，很大程度上决定了运行在上面的 Java 虚拟机的线程怎样去映射，但是这一点在不同的平台上很难达成一致。
所以JVM 规范里面没有、也不好去规定 Java 线程需要使用哪种线程模型来实现。
同时关于本文要讨论的话题，我在知乎上也找到了类似的问题：
 https://www.zhihu.com/question/64072646/answer/216184631
 这里面有一个R大的回答，大家可以看看一下。
他也是先从线程模型的角度铺垫了一下。
我这里主要说一下使用内核线程实现（1:1实现）的这个模型。
因为我们用的最多的 HotSpot 虚拟机，就是采用 1:1 模型来实现 Java 线程的。
这是个啥意思呢？
说人话就是一个 Java 线程是直接映射为一个操作系统原生线程的，中间没有额外的间接结构。HotSpot 虚拟机也不干涉线程的调度，这事全权交给底下的操作系统去做。</description>
    </item>
    
    <item>
      <title>Java协程</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%8D%8F%E7%A8%8B/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/java%E5%8D%8F%E7%A8%8B/</guid>
      <description>1. 现状 时至今日，JDK17已经正式发布，Java也没有在语言层面对协程提供原生支持。
一定要在Java中使用协程的话，可以使用诸如quasar, kilim, coroutines 第三方库感受一下，它们的原理基本都是字节码增强 + Java Agent机制，这种做法一是对性能影响很大，对JIT编译器的影响也非常大，另外这些库都几年前就不在更新了，远达不到生产使用的标准。
还可以使用Kotlin混合编程，Kotlin中的协程本质上还是一套基于原生Java Thread API 的封装，和Go中的协程完全不是一个东西，不要混淆，更谈不上什么性能更好，Kotlin中的协程最大的价值是写起来比RxJava的线程切换还要方便，几乎就是用阻塞的写法来完成非阻塞的任务。
openjdk也有正在孵化的官方协程项目loom，其能否release还需拭目以待。
2. 成因 是什么原因导致Oracle一直不着急推出对协程的支持呢？
先返回到问题的本源。当我们希望引入协程，我们想解决什么问题。我想不外乎下面几点：
  节省资源：节省内存、节省分配线程的开销（创建和销毁线程要各做一次syscall）、节省大量线程切换带来的开销
  与NIO配合实现非阻塞的编程，提高系统的吞吐
  使用起来更加舒服顺畅，同步的编程风格编写异步程序
  2.1 节省资源 1. 节省内存 我们以常见的Java Web举例，spingboot分配给tomcat的线程池大小默认值是200，即使按照1M线程大小计算，200M的内存占用对于动辄几个G的Java Web应用并不算什么。
即使是IM的场景，有数百万的长链接需要维护，也可以使用NIO+Worker线程应对。
还可以调整线程栈占用内存大小（-Xss1024k 或者 -XX:ThreadStackSize=1024k）
2. 节省线程分配开销 线程池
3. 节省线程切换开销 我们仍然以Java Web举例，大量的线程大部分时间实际上因为IO（发请求/读DB）而挂起，根本不会参与OS的线程切换，现实当中一个最大200线程的服务器可能同一时刻的“活跃线程”总数只有数十而已。其开销没有想象的那么大。
2.2 非阻塞编程 nio 👉 netty
2.3 优雅异步编程 响应式编程库
可见Java对于引入协程机制并不那么紧迫；并且Java不像Golang等新语言，没有历史包袱，它们可以不提供线程只提供协程编程，但是Java如果没有thread，也没有ThreadLocal，@Transactional不起作用了，又没有等价的工具，是不是很郁闷？
参考 为什么 Java 坚持多线程不选择协程？
Kotlin 协程真的比 Java 线程更高效吗？
硬核系列 | 深入剖析 Java 协程</description>
    </item>
    
    <item>
      <title>JIT即时编译</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/jit%E5%8D%B3%E6%97%B6%E7%BC%96%E8%AF%91/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/jit%E5%8D%B3%E6%97%B6%E7%BC%96%E8%AF%91/</guid>
      <description>JIT (just-in-time compilation) 是指程序在运行过程中对热点代码进行编译的过程，编译后的机器码存入CodeCache，下次再遇到这段代码，就会从CodeCache中读取机器码，直接执行，以此来提升程序运行的性能。
有的JVM全程都是JIT编译运行，例如：JRockit；有的JVM是解释器 + JIT运行，例如：HotSpot, J9（也支持AOT）；有的JVM没有解释器，只支持AOT+JIT或者纯AOT，例如：Excelsior JET
以HotSpot JVM举例，JIT还可以分为C1, C2等。C1编译快，执行效率低；C2编译慢，效率高。可以通过 -XX:+TieredCompilation 开启分层编译，对热点代码先C1编译以尽快进入到编译执行模式；随着应用继续运行，收集到足够多的指标后，再进行C2编译，以期获得最好的执行效率。
JIT在编译过程中会采用一些优化手段，包括：公共子表达式消除、数组范围检查消除、方法内联、逃逸分析（目的是栈上分配、同步消除、标量替换、循环变型、窥孔优化与寄存器分配）
1. 编译器与解释器 不做特别说明的话，我们讲的，
编译器：程序运行前将其编译成机器码的程序
解释器：程序运作中逐行解释源码得到结果的程序
 特别注意的是，解释器也是一个程序，输入源码，输出结果，并没有显示的将源码转换成机器码的过程 解释器与 JIT
 无论是编译器还是解释器，从 源码 到结果都需要将源码经过：词法分析 -&amp;gt; 语法分析 -&amp;gt; 语义分析 处理，
一个比较简单的编译器的处理步骤看起来：
编译流程： 源码 [字符流] - 词法分析 -&amp;gt; 单词（token）流 - 语法分析 -&amp;gt; 语法树 / 抽象语法树 - 语义分析 -&amp;gt; 标注了属性的抽象语法树 - 代码生成 -&amp;gt; 目标代码 执行流程： 目标代码 - 操作系统/硬件 -&amp;gt; 执行结果 狭义的解释器处理步骤看起来：
解释执行流程： 源码 [字符流] - 需要做词法分析+语法分析+类型检查的字符流解释器 -&amp;gt; 执行结果  特别注意的是，解释器真正的输入往往并直接是源码，使用解释器实现的编程语言实现里，通常：</description>
    </item>
    
    <item>
      <title>Maven基础</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/maven/maven%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/maven/maven%E5%9F%BA%E7%A1%80/</guid>
      <description>1. 问题 项目开发过程中，经常会遇到jar冲突，然后maven根据自己的规则进行冲突解决，导致项目在运行的过程中报错。
1、maven自动解决依赖冲突的规则是什么？
2、如何查看当前项目的maven的依赖树？
3、如何从依赖树中找到自己预期的版本，是被那个jar给覆盖了？
4、如何人工进行依赖冲突解决，达到使用目的？
2. 解决问题 2.1 maven自动解决依赖冲突的规则是什么？ 2.1.1 第一原则：路径最近者优先 项目A有如下的依赖关系：
A-&amp;gt;B-&amp;gt;C-&amp;gt;X(1.0)
A-&amp;gt;D-&amp;gt;X(2.0)
则该例子中，X的版本是2.0
2.1.2 第二原则：路径相等，先声明者优先 项目A有如下的依赖关系：
A-&amp;gt;B-&amp;gt;Y(1.0)
A-&amp;gt;C-&amp;gt;Y(2.0)
若pom文件中B的依赖坐标先于C进行声明，则最终Y的版本为1.0
2.2 如何查看当前项目的maven依赖树？ //进入项目的pom.xml文件的目录下，运行如下命令 //这个是正常依赖的树 mvn dependency:tree //这个命令是查看maven是如何解决依赖冲突的依赖树 mvn -Dverbose dependency:tree //如果想将依赖树打印到指定文件中，则命令如下 mvn -Dverbose dependency:tree -Doutput=/Users/shangxiaofei/sxfoutput.txt 3. 如何从依赖树中找到自己预期的版本，是被那个jar给覆盖了？ 例子：
递归依赖的关系列的算是比较清楚了，每行都是一个jar包，根据缩进可以看到依赖的关系。
最后写着compile的就是编译成功的。
最后写着omitted for duplicate的就是有jar包被重复依赖了，但是jar包的版本是一样的。
最后写着omitted for conflict with xxxx的，说明和别的jar包版本冲突了，而该行的jar包不会被引入。比如上面有一行最后写着omitted for conflict with 3.4.6，那么该行的zookeeper🫙3.4.8不会被引入，会引入3.4.6版本
最后写着version managed from 2.3 ;omitted for duplicate ,表示最终使用commons-pool2最终会使用2.4.2，拒绝使用中声明的2.3版本
最后写着version managed from 1.16.8 ;表示最终使用lombok🫙1.16.22版本
4. 如何人工进行依赖冲突解决，达到使用目的？ 解决重复依赖和冲突的方法：</description>
    </item>
    
    <item>
      <title>MongoDB综述</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mongodb/mongodb%E7%BB%BC%E8%BF%B0/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mongodb/mongodb%E7%BB%BC%E8%BF%B0/</guid>
      <description>MongoDB综述 参考 项目实战 MongoDB快速入门，掌握这些刚刚好！
mall整合Mongodb实现文档操作</description>
    </item>
    
    <item>
      <title>MQ消息最终一致性解决方案</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mq/mq%E6%B6%88%E6%81%AF%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mq/mq%E6%B6%88%E6%81%AF%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</guid>
      <description>只有RocketMQ支持事务消息，如果我们的MQ不是RocketMQ，可以采用本地消息+MQ达到同样的效果，并且本地消息表还可以做出独立的服务。
随着分布式服务架构的流行与普及，原来在单体应用中执行的多个逻辑操作，现在被拆分成了多个服务之间的远程调用。虽然服务化为我们的系统带来了水平伸缩的能力，然而随之而来挑战就是分布式事务问题，多个服务之间使用自己单独维护的数据库，它们彼此之间不在同一个事务中，假如A执行成功了，B执行却失败了，而A的事务此时已经提交，无法回滚，那么最终就会导致两边数据不一致性的问题；尽管很早之前就有基于两阶段提交的XA分布式事务，但是这类方案因为需要资源的全局锁定，导致性能极差；因此后面就逐渐衍生出了消息最终一致性、TCC等柔性事务的分布式事务方案，本文主要分析的是基于消息的最终一致性方案。
0\. 简单RPC处理存在的一致性问题 在正式开始讲述正题之前，我们先看一下，不依赖任何分布式事务手段，单纯将本地业务逻辑和远程调用逻辑放在同一个本地事务中会有什么问题。
我们以订单创建为例，订单系统先创建订单(本地事务)，然后RPC调用库存扣减服务。
@Transactionnal public void processOrder() {  try{  // 订单处理(业务操作)  orderService.process();  // 库存扣减（RPC远程调用）  storageService.deduction();  }catch(Exception e){  事务回滚;  } } 如果库存服务由于DB数据量比较大，导致处理超时，订单服务在出现超时异常后，直接回滚本地事务，从而导致订单服务这边没数据，而库存服务那边数据却已经写入了，最终导致两边业务数据的不一致。
即使不存在 “DB数据量比较大” 这种特殊情况，也一定会存在因为网络抖动，订单服务调用库存服务超时而本地回滚，但是库存服务实际操作成功的情况。
其根本的原因就在于：远程调用，结果最终可能为成功、失败、超时；而对于超时的情况，处理方最终的结果可能是成功，也可能是失败，调用方是无法知晓的。
1\. 普通消息的处理流程  消息生成者发送消息 MQ收到消息，将消息进行持久化，在存储中新增一条记录 返回ACK给生产者 MQ push 消息给对应的消费者，然后等待消费者返回ACK 如果消息消费者在指定时间内成功返回ack，那么MQ认为消息消费成功，在存储中删除消息，即执行第6步；如果MQ在指定时间内没有收到ACK，则认为消息消费失败，会尝试重新push消息,重复执行4、5、6步骤 MQ删除消息  1.2 普通消息处理存在的一致性问题 我们还是以订单创建为例，订单系统先创建订单(本地事务)，再发送消息给下游处理；如果订单创建成功，然而消息没有发送出去，那么下游所有系统都无法感知到这个事件，会出现脏数据；
public void processOrder() {  // 订单处理(业务操作)  orderService.process();  // 发送订单处理成功消息(发送消息)  sendBizMsg (); } 如果先发送订单消息，再创建订单；那么就有可能消息发送成功，但是在订单创建的时候却失败了，此时下游系统却认为这个订单已经创建，也会出现脏数据。
public void processOrder() {  // 发送订单处理成功消息(发送消息)  sendBizMsg ();  // 订单处理(业务操作)  orderService.</description>
    </item>
    
    <item>
      <title>MQ综述</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mq/mq%E7%BB%BC%E8%BF%B0/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mq/mq%E7%BB%BC%E8%BF%B0/</guid>
      <description>1. 概念  Broker Producer Consumer Topic Queue Message  2. 模式 2.1. 点对点 PTP 点对点: 使用 Queue 作为通信载体
消息生产者生产消息发送到 Queue 中，然后消息消费者从 Queue 中取出并且消费消息。消息被消费以后，Queue 中不再存储，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费
2.2. 发布/订阅 Pub/Sub 发布订阅(广播): 使用 Topic 作为通信载体
消息生产者(发布)将消息发布到 Topic 中，同时有多个消息消费者(订阅)消费该消息。和点对点方式不同，发布到 Topic 的消息会被所有订阅者消费
总结 Queue 实现了负载均衡，将 Producer 生产的消息发送到消息队列中，由多个消费者消费。但一个消息只能被一个消费者接受，当没有消费者可用时，这个消息会被保存直到有一个可用的消费者
Topic 实现了发布和订阅，当你发布一个消息，所有订阅这个 Topic 的服务都能得到这个消息，所以从1到N个订阅者都能得到一个消息的拷贝
3. 协议 3.1. AMQP协议 AMQP 即 Advanced Message Queuing Protocol ，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。兼容 JMS。RabbitMQ 就是基于 AMQP 协议实现的。
优点：可靠、通用
 JMS（JAVA Message Service,java 消息服务）是 java 的消息服务，JMS 的客户端之间可以通过 JMS 服务进行异步的消息传输。JMS（JAVA Message Service，Java 消息服务）API 是一个消息服务的标准或者说是规范，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。</description>
    </item>
    
    <item>
      <title>MySQL Integer类型与INT(11)</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/mysql-integer%E7%B1%BB%E5%9E%8B%E4%B8%8Eint11/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/mysql-integer%E7%B1%BB%E5%9E%8B%E4%B8%8Eint11/</guid>
      <description>1.介绍 Integer类型，即整数类型，MySQL支持的整数类型有TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT。
1.1 空间和范围 每种整数类型所需的存储空间和范围如下：
   类型 字节 最小值(有符号) 最大值(有符号) 最小值(无符号) 最大值(无符号)     TINYINT 1 -128 127 0 255   SMALLINT 2 -32768 32767 0 65535   MEDIUMINT 3 -8388608 8388607 0 16777215   INT 4 -2147483648 2147483647 0 4294967295   BIGINT 8 $-2^{63}$(-9223372036854775808) $2^{63}-1$(9223372036854775807) 0 $2^{64}-1$(18446744073709551615)    2. INT(11) 2.1 数字是否限制长度？ id INT(11) NOT NULL AUTO_INCREMENT, 在一些建表语句会出现上面 int(11) 的类型，那么其代表什么意思呢？</description>
    </item>
    
    <item>
      <title>MySQL前缀索引</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/mysql%E5%89%8D%E7%BC%80%E7%B4%A2%E5%BC%95/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/mysql%E5%89%8D%E7%BC%80%E7%B4%A2%E5%BC%95/</guid>
      <description>参考 MySQL 前缀索引
前缀索引，一种优化索引大小的解决方案</description>
    </item>
    
    <item>
      <title>MySQL日志</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/mysql%E6%97%A5%E5%BF%97/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/mysql%E6%97%A5%E5%BF%97/</guid>
      <description>日志是mysql数据库的重要组成部分，记录着数据库运行期间各种状态信息。mysql日志主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。作为开发，我们重点需要关注的是二进制日志(binlog)和事务日志(包括redo log和undo log)，本文接下来会详细介绍这三种日志。其他几种日志见 👉 [玩转MySQL之八]MySQL日志分类及简介
1. binlog binlog用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。binlog是mysql的逻辑日志，并且由Server层进行记录，使用任何存储引擎的mysql数据库都会记录binlog日志。
 逻辑日志：可以简单理解为记录的就是sql语句。
  物理日志：因为mysql数据最终是保存在数据页中的，物理日志记录的就是数据页变更。
 binlog是通过追加的方式进行写入的，可以通过max_binlog_size参数设置每个binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。
1.1 binlog使用场景 在实际应用中，binlog的主要使用场景有两个，分别是主从复制和数据恢复。
 主从复制：在Master端开启binlog，然后将binlog发送到各个Slave端，Slave端重放binlog从而达到主从数据一致。 数据恢复：通过使用mysqlbinlog工具来恢复数据。  1.2 binlog刷盘时机 对于InnoDB存储引擎而言，只有在事务提交时才会记录biglog，此时记录还在内存中，那么biglog是什么时候刷到磁盘中的呢？mysql通过sync_binlog参数控制biglog的刷盘时机，取值范围是0-N：
 0：不去强制要求，由系统自行判断何时写入磁盘； 1：每次commit的时候都要将binlog写入磁盘； N：每N个事务，才会将binlog写入磁盘。  从上面可以看出，sync_binlog最安全的是设置是1，这也是MySQL 5.7.7之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。
1.3 binlog日志格式 binlog日志有三种格式，分别为STATMENT、ROW和MIXED。
 在 MySQL 5.7.7之前，默认的格式是STATEMENT，MySQL 5.7.7之后，默认值是ROW。日志格式通过binlog-format指定。
  STATMENT 基于SQL语句的复制(statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。 优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO, 从而提高了性能； 缺点：在某些情况下会导致主从数据不一致，比如执行sysdate()、slepp()等。 ROW 基于行的复制(row-based replication, RBR)，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了。 优点：不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题； 缺点：会产生大量的日志，尤其是alter table的时候会让日志暴涨 MIXED 基于STATMENT和ROW两种模式的混合复制(mixed-based replication, MBR)，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog  2. redo log 2.1 为什么需要redo log 我们都知道，事务的四大特性里面有一个是 持久性，具体来说就是只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态。那么mysql是如何保证持久性的呢？最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题，主要体现在两个方面：
 因为Innodb是以页为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！ 一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差！  因此mysql设计了redo log，具体来说就是只记录事务对数据页做了哪些修改，这样就能完美地解决性能问题了(相对而言文件更小并且是顺序IO)。MySQL实战45讲中将redo log比作临时记账的粉板，实际数据页比作账本。</description>
    </item>
    
    <item>
      <title>MySQL索引的工作原理</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/mysql%E7%B4%A2%E5%BC%95%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/mysql%E7%B4%A2%E5%BC%95%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</guid>
      <description>索引是一种加快查询的数据结构，在 MySQL 中，索引的数据结构选择的是 B+Tree，至于 B+Tree 是什么以及为什么 MySQL 为什么选择 B+Tree 来作为索引，可以去查看公众号的前三篇文章。
  索引数据结构之 B-Tree 与 B+Tree（上篇）
  索引数据结构之 B-Tree 与 B+Tree（下篇）
  MySQL 为什么不用数组、哈希表、二叉树等数据结构作为索引呢
  今天主要来聊聊 MySQL 中索引的工作原理，这一部分的知识，在工作中经常被使用到，在面试中也几乎是必问的。所以，不管是面试造火箭，还是工作拧螺丝，掌握索引的工作原理，都是十分有必要的。
首先需要说明的是，本文的所有讨论均是基于 InnoDB 存储引擎为前提。
示例表 为了方便说明，我们先创建一个示例表。建表语句如下
CREATE TABLE user ( `id` BIGINT ( 11 ) NOT NULL AUTO_INCREMENT, `name` VARCHAR ( 64 ) COMMENT &amp;#39;姓名&amp;#39;, `age` INT ( 4 ) COMMENT &amp;#39;年龄&amp;#39;, PRIMARY KEY ( `id` ), INDEX ( NAME ) ) ENGINE = INNODB COMMENT &amp;#39;用户表&amp;#39;;  INSERT INTO `user` ( `name`, `age` ) VALUES ( &amp;#39;AA&amp;#39;, 30 ),( &amp;#39;BB&amp;#39;, 33 ),( &amp;#39;CC&amp;#39;, 31 ),( &amp;#39;DD&amp;#39;, 30 ),( &amp;#39;EE&amp;#39;, 29 ) 在上面的 SQL 语句中，创建了一张 user 表，表中有三个字段，id 是主键，name 和 age 分别表示用户的姓名和年龄，同时还为字段 name 创建了一个普通索引。为了方便后面描述，因此还向表中插入了 5 条数据，由于主键 id 是自增的，所以这五行数据的 id 值分为是 1~5。</description>
    </item>
    
    <item>
      <title>nginx授权登陆报403问题</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/nginx/nginx%E6%8E%88%E6%9D%83%E7%99%BB%E9%99%86%E6%8A%A5403%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/nginx/nginx%E6%8E%88%E6%9D%83%E7%99%BB%E9%99%86%E6%8A%A5403%E9%97%AE%E9%A2%98/</guid>
      <description>在给nginx加上授权模块后，再访问应用报403访问禁止的错误。
一开始是这样：
1. 生成密码文件 printf &amp;#34;yourusername:$(openssl passwd -apr1)&amp;#34; &amp;gt; /etc/nginx/passwords 2. nginx配置 server {  # ...  auth_basic &amp;#34;Protected&amp;#34;;  auth_basic_user_file passwords;  # ... } [v_error]auth_basic_user_file 后面跟的是相对路径，这样配置很容易导致nginx找不到文件，因此改成绝对路径就万事大吉了：[/v_error]
server{		listen 443 ssl; 	server_name netdata.6and.ltd;  #listen [::]:81 default_server ipv6only=on; 	#ssl on; 	ssl_certificate httpssl/1_netdata.6and.ltd_bundle.crt; 	ssl_certificate_key httpssl/2_netdata.6and.ltd.key; 	ssl_session_timeout 5m; 	ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;  ssl_protocols TLSv1 TLSv1.1 TLSv1.2; 	ssl_prefer_server_ciphers on; 	#index index.html index.htm index.php; 	#root /home/wwwroot/;  	#error_page 404 /404.</description>
    </item>
    
    <item>
      <title>OOM实战</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/oom%E5%AE%9E%E6%88%98/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/oom%E5%AE%9E%E6%88%98/</guid>
      <description>《深入理解Java虚拟机》中将OOM划分为: Java堆溢出、虚拟机栈和本地方法栈溢出、方法区和运行时常量池溢出、本机直接内存溢出
1. Java堆溢出 /** * JDK1.6/JDK1.8 * * Java堆内存溢出异常测试 * * VM Args: -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError * * @author xuzhijun.online * @date 2019年4月22日 */ public class HeapOOM {   static class OOMObject{   }   public static void main(String[] args) {  List&amp;lt;OOMObject&amp;gt; list = new ArrayList&amp;lt;OOMObject&amp;gt;();  while(true) {  list.add(new OOMObject());  }  }  } 运行结果：
java.lang.OutOfMemoryError: Java heap space Dumping heap to java_pid3404.</description>
    </item>
    
    <item>
      <title>openresty最佳实践</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/openresty/openresty%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/openresty/openresty%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid>
      <description>推荐先阅读下面文章，以储备基础知识。
方志朋openresty系列：openresty最佳案例案例-汇总
黑马程序员：java自学进阶高性能web平台openresty简介</description>
    </item>
    
    <item>
      <title>Redisson原理</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/redis/redisson%E5%8E%9F%E7%90%86/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/redis/redisson%E5%8E%9F%E7%90%86/</guid>
      <description>使用 set key value ex/px 秒/毫秒 xx/nx 的命令实现分布式锁，存在多个client端加锁成功的极端情况。Redisson使用RedLock可以避免这个问题，其原理是多锁，例如对多个哨兵集群加不同的锁，只有超半数以上的哨兵集群反馈加锁成功才算加锁成功。另外，Redisson还通过WatchDog实现了锁续租。还实现了很多有用的数据结构（RedissonPriorityDeque）和分布式同步工具（RedissonCountDownLatch, RedissonSemaphore）
写在前面 在了解分布式锁具体实现方案之前，我们应该先思考一下使用分布式锁必须要考虑的一些问题。
 互斥性：在任意时刻，只能有一个进程持有锁。 防死锁：即使有一个进程在持有锁的期间崩溃而未能主动释放锁，要有其他方式去释放锁从而保证其他进程能获取到锁。 加锁和解锁的必须是同一个进程。 锁的续期问题。  常见的分布式锁实现方案  基于 Redis 实现分布式锁 基于 Zookeeper 实现分布式锁  本文采用第一种方案，也就是基于 Redis 的分布式锁实现方案。
Redis 实现分布式锁主要步骤  指定一个 key 作为锁标记，存入 Redis 中，指定一个 唯一的用户标识 作为 value。 当 key 不存在时才能设置值，确保同一时间只有一个客户端进程获得锁，满足 互斥性 特性。 设置一个过期时间，防止因系统异常导致没能删除这个 key，满足 防死锁 特性。 当处理完业务之后需要清除这个 key 来释放锁，清除 key 时需要校验 value 值，需要满足 只有加锁的人才能释放锁 。   特别注意：以上实现步骤考虑到了使用分布式锁需要考虑的互斥性、防死锁、加锁和解锁必须为同一个进程等问题，但是锁的续期无法实现。所以，博主采用 Redisson 实现 Redis 的分布式锁，借助 Redisson 的 WatchDog 机制 能够很好的解决锁续期的问题，同样 Redisson 也是 Redis 官方推荐分布式锁实现方案，实现起来较为简单。</description>
    </item>
    
    <item>
      <title>redis分布式锁和zk分布式锁的对比</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/zookeeper/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%92%8Czk%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AF%B9%E6%AF%94/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/zookeeper/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%92%8Czk%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AF%B9%E6%AF%94/</guid>
      <description>redis 分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能。 zk 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。  另外一点就是，如果是 Redis 获取锁的那个客户端 出现 bug 挂了，那么只能等待超时时间之后才能释放锁；而 zk 的话，因为创建的是临时 znode，只要客户端挂了，znode 就没了，此时就自动释放锁。
Redis 分布式锁大家没发现好麻烦吗？遍历上锁，计算时间等等&amp;hellip;&amp;hellip;zk 的分布式锁语义清晰实现简单。
所以先不分析太多的东西，就说这两点，我个人实践认为 zk 的分布式锁比 Redis 的分布式锁牢靠、而且模型简单易用。
参考 一般实现分布式锁都有哪些方式？使用 Redis 如何设计分布式锁？使用 zk 来设计分布式锁可以吗？这两种分布式锁的实现方式哪种效率比较高？</description>
    </item>
    
    <item>
      <title>Redis配置指南</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/redis/redis%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/redis/redis%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/</guid>
      <description>1. 安装 $ wget http://download.redis.io/releases/redis-5.0.8.tar.gz $ tar xzf redis-5.0.8.tar.gz $ cd redis-5.0.8 $ make 2.配置  注释掉bind 127.0.0.1 protected-mode yes requirepass xxxpassword daemonize yes  3. 启动 cd src ./redis-server 或者
cd src ./redis-server ../redis.conf 4. 停止 cd src ./redis-cli auth xxxpassword shutdown exit 5. 卸载 find / -name &amp;#34;redis*&amp;#34; | xargs rm -rf 6.远程连接 window连接远程redis:
redis-cli -h 193.112.37.xxx -p 6379 -a xxxpassword </description>
    </item>
    
    <item>
      <title>Redis主从复制</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/redis/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/redis/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</guid>
      <description>主从复制虽然实现数据冗余（是持久化之外的一种数据冗余方式）、故障恢复（手动切换）、读负载均衡等问题。但无法自动故障转移、写操作无法负载均衡、存储能力受到单机的限制。
1. 主从复制概述 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。
默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。
主从复制的作用
主从复制的作用主要包括：
 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。  2. 如何使用主从复制 为了更直观的理解主从复制，在介绍其内部原理之前，先说明我们需要如何操作才能开启主从复制。
2.1 建立复制 需要注意，主从复制的开启，完全是在从节点发起的；不需要我们在主节点做任何事情。
从节点开启主从复制，有3种方式：
（1）配置文件
在从服务器的配置文件中加入：slaveof  
（2）启动命令
redis-server启动命令后加入 &amp;ndash;slaveof  
（3）客户端命令
Redis服务器启动后，直接通过客户端执行命令：slaveof  ，则该Redis实例成为从节点。
上述3种方式是等效的，下面以客户端命令的方式为例，看一下当执行了slaveof后，Redis主节点和从节点的变化。
2.2 实例 准备工作：启动两个节点 方便起见，实验所使用的主从节点是在一台机器上的不同Redis实例，其中主节点监听6379端口，从节点监听6380端口；从节点监听的端口号可以在配置文件中修改：
启动后可以看到：
两个Redis节点启动后（分别称为6379节点和6380节点），默认都是主节点。
建立复制 此时在6380节点执行slaveof命令，使之变为从节点：
观察效果 下面验证一下，在主从复制建立后，主节点的数据会复制到从节点中。
（1）首先在从节点查询一个不存在的key：
（2）然后在主节点中增加这个key：
（3）此时在从节点中再次查询这个key，会发现主节点的操作已经同步至从节点：
（4）然后在主节点删除这个key：
（5）此时在从节点中再次查询这个key，会发现主节点的操作已经同步至从节点：
2.3 断开复制 通过slaveof  命令建立主从复制关系以后，可以通过slaveof no one断开。需要注意的是，从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。
从节点执行slaveof no one后，打印日志如下所示；可以看出断开复制后，从节点又变回为主节点。
主节点打印日志如下：
3. 主从复制的实现原理 上面一节中，介绍了如何操作可以建立主从关系；本小节将介绍主从复制的实现原理。
主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段；下面分别进行介绍。
3.1 连接建立阶段 该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备。
步骤1：保存主节点信息 从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。
需要注意的是，slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK**，实际的复制操作在这之后才开始进行。**</description>
    </item>
    
    <item>
      <title>Spring Security第一次登录失败，第二次登录成功</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/exception/spring-security%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%99%BB%E5%BD%95%E5%A4%B1%E8%B4%A5%E7%AC%AC%E4%BA%8C%E6%AC%A1%E7%99%BB%E5%BD%95%E6%88%90%E5%8A%9F/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/exception/spring-security%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%99%BB%E5%BD%95%E5%A4%B1%E8%B4%A5%E7%AC%AC%E4%BA%8C%E6%AC%A1%E7%99%BB%E5%BD%95%E6%88%90%E5%8A%9F/</guid>
      <description>当我第一次登录时我会得到{&amp;quot; timestamp&amp;quot;：1481719982036，&amp;quot; status&amp;quot;：999，&amp;quot; error&amp;quot;：&amp;quot; None&amp;quot;，&amp;quot; message&amp;quot;：&amp;quot;无可用消息&amp;quot;}，但第二次还可以。
解决办法：填写如下配置到application.properties
spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration 参考链接：java:Spring Security第一次登录失败，第二次登录成功</description>
    </item>
    
    <item>
      <title>SpringAOP方法内部调用不生效</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/spring/springaop%E6%96%B9%E6%B3%95%E5%86%85%E9%83%A8%E8%B0%83%E7%94%A8%E4%B8%8D%E7%94%9F%E6%95%88/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/spring/springaop%E6%96%B9%E6%B3%95%E5%86%85%E9%83%A8%E8%B0%83%E7%94%A8%E4%B8%8D%E7%94%9F%E6%95%88/</guid>
      <description>假设一个接口里面有两个方法：
package demo.long;  public interface CustomerService {  public void doSomething1();  public void doSomething2(); } 接口实现类如下：
package demo.long.impl;  import demo.long.CustomerService;  public class CustomerServiceImpl implements CustomerService {   public void doSomething1() {  System.out.println(&amp;#34;CustomerServiceImpl.doSomething1()&amp;#34;);  doSomething2();  }   public void doSomething2() {  System.out.println(&amp;#34;CustomerServiceImpl.doSomething2()&amp;#34;);  }  } 现在我需要在CustomerService接口的每个方法被调用时都在方法前执行一些逻辑，所以需要配置一个拦截器：
package demo.long;  import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before;  @Aspect public class CustomerServiceInterceptor {   @Before(&amp;#34;execution(* demo.</description>
    </item>
    
    <item>
      <title>SpringBoot使用QQ邮箱发送邮件配置</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/spring/springboot/springboot%E4%BD%BF%E7%94%A8qq%E9%82%AE%E7%AE%B1%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/spring/springboot/springboot%E4%BD%BF%E7%94%A8qq%E9%82%AE%E7%AE%B1%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E9%85%8D%E7%BD%AE/</guid>
      <description>使用SpringBoot Admin 配置QQ邮箱去发送邮件时报错：com.sun.mail.smtp.SMTPSenderFailedException: 501 mail from address must be same as authorization user，我的配置如下：
spring.mail.host: smtp.qq.com spring.mail.username: 发送账号 spring.mail.password: qq授权码 spring.boot.admin.notify.mail.to: 接收账号 后来在网上查到是少了spring.boot.admin.notify.mail.from的配置，貌似只有QQ邮箱才需要额外加上这个设置（本人没有测试过用其他邮箱发送邮件）。所以最终配置如下：
spring.mail.host: smtp.qq.com spring.mail.username: 发送账号 spring.mail.password: qq授权码 spring.boot.admin.notify.mail.to: 接收账号 spring.boot.admin.notify.mail.from: 发送账号 参考： Springboot admin 发送邮件失败：com.sun.mail.smtp.SMTPSenderFailedException: 553 Mail from must equal authorized user</description>
    </item>
    
    <item>
      <title>SpringMVC</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/spring/springmvc/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/spring/springmvc/</guid>
      <description>SpringMVC执行流程  用户发送请求至前端控制器DispatcherServlet DispatcherServlet收到请求调用处理器映射器HandlerMapping。 处理器映射器根据请求url找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。 DispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作 执行处理器Handler(Controller，也叫页面控制器)。 Handler执行完成返回ModelAndView HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet DispatcherServlet将ModelAndView传给ViewReslover视图解析器 ViewReslover解析后返回具体View DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。 DispatcherServlet响应用户。  组件说明  DispatcherServlet：前端控制器。用户请求到达前端控制器，它就相当于mvc模式中的c，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性,系统扩展性提高。由框架实现 HandlerMapping：处理器映射器。HandlerMapping负责根据用户请求的url找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，根据一定的规则去查找,例如：xml配置方式，实现接口方式，注解方式等。由框架实现 Handler：处理器。Handler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。由于Handler涉及到具体的用户业务请求，所以一般情况需要程序员根据业务需求开发Handler。 HandlAdapter：处理器适配器。通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。由框架实现。 ModelAndView是springmvc的封装对象，将model和view封装在一起。 ViewResolver：视图解析器。ViewResolver负责将处理结果生成View视图，ViewResolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 View: 是springmvc的封装对象，是一个接口, springmvc框架提供了很多的View视图类型，包括：jspview，pdfview,jstlView、freemarkerView、pdfView等。一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开发具体的页面。  参考链接： SpringMVC执行流程及工作原理
Spring MVC【入门】就这一篇！</description>
    </item>
    
    <item>
      <title>Spring事务</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/spring/spring%E4%BA%8B%E5%8A%A1/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/spring/spring%E4%BA%8B%E5%8A%A1/</guid>
      <description>Spring事务可简单的理解为由PlatformTransactionManager, TransactionDefinition, TransactionStatus 构成
PlatformTransactionManager 其中 org.springframework.transaction.PlatformTransactionManager 接口定义如下：
public interface PlatformTransactionManager extends TransactionManager {  // Return a currently active transaction or create a new one, according to the specified propagation behavior（根据指定的传播行为，返回当前活动的事务或创建一个新事务。）  TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException;  // Commit the given transaction, with regard to its status（使用事务目前的状态提交事务）  Void commit(TransactionStatus status) throws TransactionException;  // Perform a rollback of the given transaction（对执行的事务进行回滚）  Void rollback(TransactionStatus status) throws TransactionException; } Spring并不直接管理事务，它只提供接口抽象，事务管理器的具体实现由持久化框架自己实现，例如：DataSourceTransactionManager (JDBC / MyBatis),</description>
    </item>
    
    <item>
      <title>Spring优雅的异常处理</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/spring/spring%E4%BC%98%E9%9B%85%E7%9A%84%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/spring/spring%E4%BC%98%E9%9B%85%E7%9A%84%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</guid>
      <description>SpringBoot的WEB异常捕获，如果是WEB项目的话，可以直接处理Controller中的异常。如果不是WEB项目的话，就需要使用AspectJ来做切面。
1. web项目 package com.test.handler;  import lombok.extern.log4j.Log4j2; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.ControllerAdvice; import org.springframework.web.bind.annotation.ExceptionHandler;   @ControllerAdvice @Log4j2 public class GlobalExceptionHandler {  @ExceptionHandler(value = Exception.class)  public String exception(Exception e, Model model){  log.error(&amp;#34;find exception:e={}&amp;#34;,e.getMessage());  model.addAttribute(&amp;#34;mes&amp;#34;,e.getMessage());  return &amp;#34;pages/500&amp;#34;;  } } 参考链接：
SpringBootWEB项目和非Web项目的全局异常捕获
SpringBoot 处理异常的几种常见姿势
使用枚举简单封装一个优雅的 Spring Boot 全局异常处理！
2. 非web项目 package com.test.syncbackend.handler;  import lombok.extern.log4j.Log4j2; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.springframework.stereotype.Component;  @Component @Aspect @Log4j2 public class GlobalExceptionHandler {   @Pointcut(&amp;#34;execution(* com.</description>
    </item>
    
    <item>
      <title>ThreadLocal</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/threadlocal/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/threadlocal/</guid>
      <description>ThreadLocal 是一个线程的本地变量，也就意味着这个变量是线程独有的，是不能与其他线程共享的，这样就可以避免资源竞争带来的多线程的问题，这种解决多线程的安全问题和lock(这里的lock 指通过synchronized 或者Lock 等实现的锁) 是有本质的区别的:
 lock 的资源是多个线程共享的，所以访问的时候需要加锁。 ThreadLocal 是每个线程都有一个副本，是不需要加锁的。 lock 是通过时间换空间的做法。 ThreadLocal 是典型的通过空间换时间的做法。  当然他们的使用场景也是不同的，关键看你的资源是需要多线程之间共享的还是单线程内部共享的。
ThreadLocal 的使用是非常简单的，看下面的代码：
public class Test {   public static void main(String[] args) {  ThreadLocal&amp;lt;String&amp;gt; local = new ThreadLocal&amp;lt;&amp;gt;();  //设置值  local.set(&amp;#34;hello word&amp;#34;);  //获取刚刚设置的值  System.out.println(local.get());  } } ThreadLocal的数据结构 为什么ThreadLocalMap 采用开放地址法来解决哈希冲突? ThreadLocal 往往存放的数据量不会特别大，这个时候开放地址法简单的结构会显得更省空间（链地址法需要额外的指针空间）
常用的hash解决方法有：拉链法（HashMap，指针需要占用空间）、开发地址（如果发生冲突，那就基于冲突位置再次探测寻址，直至不冲突，适用于记录总数可以预知的场景，如果位桶不够用就得扩容，扩容影响性能）、再hash（如果第1个hash函数冲突，那就使用第2个，多次hash是有时间成本的）
ThreadLocal应用场景 传递参数 ThreadLocal用于传递参数及优势
保证线程安全 SimpleDateFormat是线程不安全的，例如下面的写法会报错：
日期转换的一个工具类
public class DateUtil {   private static final SimpleDateFormat sdf =  new SimpleDateFormat(&amp;#34;yyyy-MM-dd HH:mm:ss&amp;#34;);   public static Date parse(String dateStr) {  Date date = null;  try {  date = sdf.</description>
    </item>
    
    <item>
      <title>ThreadLocal线程单例</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/threadlocal%E7%BA%BF%E7%A8%8B%E5%8D%95%E4%BE%8B/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/threadlocal%E7%BA%BF%E7%A8%8B%E5%8D%95%E4%BE%8B/</guid>
      <description>ThreadLocal 保证的是单个线程内部访问的是同一个实例，不同线程访问的不是同一个实例。
package test;  public class Singleton {  private static final ThreadLocal&amp;lt;Singleton&amp;gt; singleton = new ThreadLocal&amp;lt;Singleton&amp;gt;() {  @Override  protected Singleton initialValue() {  return new Singleton();  }  };   public static Singleton getInstance() {  return singleton.get();  }   private Singleton() {  } } package test;  public class T implements Runnable {  @Override  public void run() {  Singleton instance = Singleton.</description>
    </item>
    
    <item>
      <title>ThreadPoolExecutor</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/threadpoolexecutor/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/threadpoolexecutor/</guid>
      <description>如果采用有界BlockingQueue，队列满后启用maximumPoolSize，达到maximumPoolSize上限后走RejectedExecutionHandler的逻辑；如果采用无界BlockingQueue，maximumPoolSize设置无效。
构造方法 public ThreadPoolExecutor(int corePoolSize,  int maximumPoolSize,  long keepAliveTime,  TimeUnit unit,  BlockingQueue&amp;lt;Runnable&amp;gt; workQueue,  ThreadFactory threadFactory,  RejectedExecutionHandler handler) {  if (corePoolSize &amp;lt; 0 ||  maximumPoolSize &amp;lt;= 0 ||  maximumPoolSize &amp;lt; corePoolSize ||  keepAliveTime &amp;lt; 0)  throw new IllegalArgumentException();  if (workQueue == null || threadFactory == null || handler == null)  throw new NullPointerException();  this.acc = System.getSecurityManager() == null ?</description>
    </item>
    
    <item>
      <title>ZooKeeper的stat结构</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/zookeeper/zookeeper%E7%9A%84stat%E7%BB%93%E6%9E%84/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/zookeeper/zookeeper%E7%9A%84stat%E7%BB%93%E6%9E%84/</guid>
      <description>ZooKeeper命名空间中的每个znode都有一个与之关联的stat结构，类似于Unix/Linux文件系统中文件的stat结构。 znode的stat结构中的字段显示如下，各自的含义如下：
 cZxid：这是导致创建znode更改的事务ID。 mZxid：这是最后修改znode更改的事务ID。 pZxid：这是用于添加或删除子节点的znode更改的事务ID。 ctime：表示从1970-01-01T00:00:00Z开始以毫秒为单位的znode创建时间。 mtime：表示从1970-01-01T00:00:00Z开始以毫秒为单位的znode最近修改时间。 dataVersion：表示对该znode的数据所做的更改次数。 cversion：这表示对此znode的子节点进行的更改次数。 aclVersion：表示对此znode的ACL进行更改的次数。 ephemeralOwner：如果znode是ephemeral类型节点，则这是znode所有者的 session ID。 如果znode不是ephemeral节点，则该字段设置为零。 dataLength：这是znode数据字段的长度。 numChildren：这表示znode的子节点的数量。  在ZooKeeper Java shell中，可以使用stat或ls2命令查看znode的stat结构。 具体说明如下：
使用stat命令查看znode的stat结构：
[zk: localhost(CONNECTED) 0] stat /zookeeper cZxid = 0x0 ctime = Thu Jan 01 05:30:00 IST 1970 mZxid = 0x0 mtime = Thu Jan 01 05:30:00 IST 1970 pZxid = 0x0 cversion = -1 dataVersion = 0 aclVersion = 0 ephemeralOwner = 0x0 dataLength = 0 numChildren = 1 使用ls2命令查看znode的stat结构：</description>
    </item>
    
    <item>
      <title>Zookeeper服务注册发现原理</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/zookeeper/zookeeper%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%8F%91%E7%8E%B0%E5%8E%9F%E7%90%86/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/zookeeper/zookeeper%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%8F%91%E7%8E%B0%E5%8E%9F%E7%90%86/</guid>
      <description>RPC框架中有3个重要的角色：
 注册中心 ：保存所有服务的名字，服务提供者的ip列表，服务消费者的IP列表 服务提供者： 提供跨进程服务 服务消费者： 寻找到指定命名的服务并消费。  Zookeeper用作注册中心 简单来讲，zookeeper可以充当一个服务注册表（Service Registry），让多个服务提供者形成一个集群，让服务消费者通过服务注册表获取具体的服务访问地址（ip+端口）去访问具体的服务提供者。如下图所示：
具体来说，zookeeper就是个分布式文件系统，每当一个服务提供者部署后都要将自己的服务注册到zookeeper的某一路径上: /{service}/{version}/{ip:port}, 比如我们的HelloWorldService部署到两台机器，那么zookeeper上就会创建两条目录：分别为/HelloWorldService/1.0.0/100.19.20.01:16888 /HelloWorldService/1.0.0/100.19.20.02:16888。
这么描述有点不好理解，下图更直观，
在zookeeper中，进行服务注册，实际上就是在zookeeper中创建了一个znode节点，该节点存储了该服务的IP、端口、调用方式(协议、序列化方式)等。该节点承担着最重要的职责，它由服务提供者(发布服务时)创建，以供服务消费者获取节点中的信息，从而定位到服务提供者真正网络拓扑位置以及得知如何调用。RPC服务注册、发现过程简述如下：
 服务提供者启动时，会将其服务名称，ip地址注册到配置中心。 服务消费者在第一次调用服务时，会通过注册中心找到相应的服务的IP地址列表，并缓存到本地，以供后续使用。当消费者调用服务时，不会再去请求注册中心，而是直接通过负载均衡算法从IP列表中取一个服务提供者的服务器调用服务。 当服务提供者的某台服务器宕机或下线时，相应的ip会从服务提供者IP列表中移除。同时，注册中心会将新的服务IP地址列表发送给服务消费者机器，缓存在消费者本机。 当某个服务的所有服务器都下线了，那么这个服务也就下线了。 同样，当服务提供者的某台服务器上线时，注册中心会将新的服务IP地址列表发送给服务消费者机器，缓存在消费者本机。 服务提供方可以根据服务消费者的数量来作为服务下线的依据。  感知服务的下线&amp;上线 zookeeper提供了“心跳检测”功能，它会定时向各个服务提供者发送一个请求（实际上建立的是一个 socket 长连接），如果长期没有响应，服务中心就认为该服务提供者已经“挂了”，并将其剔除，比如100.19.20.02这台机器如果宕机了，那么zookeeper上的路径就会只剩/HelloWorldService/1.0.0/100.19.20.01:16888。
服务消费者会去监听相应路径（/HelloWorldService/1.0.0），一旦路径上的数据有任务变化（增加或减少），zookeeper都会通知服务消费方服务提供者地址列表已经发生改变，从而进行更新。
更为重要的是zookeeper 与生俱来的容错容灾能力（比如leader选举），可以确保服务注册表的高可用性。
使用 zookeeper 作为注册中心时，客户端订阅服务时会向 zookeeper 注册自身；主要是方便对调用方进行统计、管理。但订阅时是否注册 client 不是必要行为，和不同的注册中心实现有关，例如使用 consul 时便没有注册。
参考 Zookeeper用作注册中心的原理
8、Zookeeper服务注册与发现原理浅析
微服务中Zookeeper的应用及原理</description>
    </item>
    
    <item>
      <title>Zookeeper核心设计理解与实战</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/zookeeper/zookeeper%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E7%90%86%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/zookeeper/zookeeper%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E7%90%86%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98/</guid>
      <description>1. Zookeeper 核心架构设计 1.1 Zookeeper 特点 （1）Zookeeper 是一个分布式协调服务，是为了解决多个节点状态不一致的问题，充当中间机构来调停。如果出现了不一致，则把这个不一致的情况写入到 Zookeeper 中，Zookeeper 会返回响应，响应成功，则表示帮你达成了一致。
比如，A、B、C 节点在集群启动时，需要推举出一个主节点，这个时候，A、B、C 只要同时往 Zookeeper 上注册临时节点，谁先注册成功，谁就是主节点。
（2）Zookeeper 虽然是一个集群，但是数据并不是分散存储在各个节点上的，而是每个节点都保存了集群所有的数据。
其中一个节点作为主节点，提供分布式事务的写服务，其他节点和这个节点同步数据，保持和主节点状态一致。
（3）Zookeeper 所有节点的数据状态通过 Zab 协议保持一致。当集群中没有 Leader 节点时，内部会执行选举，选举结束，Follower 和 Leader 执行状态同步；当有 Leader 节点时，Leader 通过 ZAB 协议主导分布式事务的执行，并且所有的事务都是串行执行的。
（4）Zookeeper 的节点个数是不能线性扩展的，节点越多，同步数据的压力越大，执行分布式事务性能越差。推荐3、5、7 这样的数目。
1.1 Zookeeper 角色的理解 Zookeeper 并没有沿用 Master/Slave 概念，而是引入了 Leader，Follower，Observer 三种角色。
通过 Leader 选举算法来选定一台服务器充当 Leader 节点，Leader 服务器为客户端提供读、写服务。
Follower 节点可以参加选举，也可以接受客户端的读请求，但是接受到客户端的写请求时，会转发到 Leader 服务器去处理。
Observer 角色只能提供读服务，不能选举和被选举，所以它存在的意义是在不影响写性能的前提下，提升集群的读性能。
1.3 Zookeeper 同时满足了 CAP 吗？ 答案是否，CAP 只能同时满足其二。
Zookeeper 是有取舍的，它实现了 A 可用性、P 分区容错性、C 的写入一致性，牺牲的是 C的读一致性。</description>
    </item>
    
    <item>
      <title>ZooKeeper能做什么</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/zookeeper/zookeeper%E8%83%BD%E5%81%9A%E4%BB%80%E4%B9%88/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/zookeeper/zookeeper%E8%83%BD%E5%81%9A%E4%BB%80%E4%B9%88/</guid>
      <description>什么是ZooKeeper?官网介绍到：ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. 这大概描述了Zookeeper主要可以干哪些事情：配置管理，名字服务，提供分布式同步以及集群管理。
1. 配置管理 配置管理又被称为发布-订阅。
在我们的应用中除了代码外，还有一些就是各种配置。比如数据库连接等。一般我们都是使用配置文件的方式，在代码中引入这些配置文件。但是当我们只有一种配置，只有一台服务器，并且不经常修改的时候，使用配置文件是一个很好的做法，但是如果我们配置非常多，有很多服务器都需要这个配置，而且还可能是动态的话使用配置文件就不是个好主意了。这个时候往往需要寻找一种集中管理配置的方法，我们在这个集中的地方修改了配置，所有对这个配置感兴趣的都可以获得变更。比如我们可以把配置放在数据库里，然后所有需要配置的服务都去这个数据库读取配置。但是，因为很多服务的正常运行都非常依赖这个配置，所以需要这个集中提供配置服务的服务具备很高的可靠性。一般我们可以用一个集群来提供这个配置服务，但是用集群提升可靠性，那如何保证配置在集群中的一致性呢？ 这个时候就需要使用一种实现了一致性协议的服务了。Zookeeper就是这种服务，它使用Zab这种一致性协议来提供一致性。现在有很多开源项目使用Zookeeper来维护配置，比如在HBase中，客户端就是连接一个Zookeeper，获得必要的HBase集群的配置信息，然后才可以进一步操作。还有在开源的消息队列Kafka中，也使用Zookeeper来维护broker的信息。
应用中用到的一些配置信息放到ZK上进行集中管理。这类场景通常是这样：应用在启动的时候会主动来获取一次配置，同时，在节点上注册一个Watcher，这样一来，以后每次配置有更新的时候，都会实时通知到订阅的客户端，从来达到获取最新配置信息的目的。
2. 命名服务 命名服务也是分布式系统中比较常见的一类场景。在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。被命名的实体通常可以是集群中的机器，提供的服务地址，远程对象等等——这些我们都可以统称他们为名字（Name）。其中较为常见的就是一些分布式服务框架中的服务地址列表。通过调用ZK提供的创建节点的API，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。
阿里巴巴集团开源的分布式服务框架Dubbo中使用ZooKeeper来作为其命名服务，维护全局的服务地址列表，点击这里查看Dubbo开源项目。在Dubbo实现中： 服务提供者在启动的时候，向ZK上的指定节点/dubbo/${serviceName}/providers目录下写入自己的URL地址，这个操作就完成了服务的发布。 服务消费者启动的时候，订阅/dubbo/${serviceName}/providers目录下的提供者URL地址， 并向/dubbo/${serviceName} /consumers目录下写入自己的URL地址。 注意，所有向ZK上注册的地址都是临时节点，这样就能够保证服务提供者和消费者能够自动感应资源的变化。 另外，Dubbo还有针对服务粒度的监控，方法是订阅/dubbo/${serviceName}目录下所有提供者和消费者的信息。
3. 分布式锁 分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性。锁服务可以分为两类，一个是保持独占（排他锁），另一个是控制时序（共享锁/读锁）。
所谓保持独占（排他锁），就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 /distribute_lock节点，最终成功创建的那个客户端也即拥有了这把锁。
控制时序（共享锁/读锁）是指所有试图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里/distribute_lock已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指定）。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也形成了每个客户端的全局时序。
4. 集群管理 在分布式的集群中，经常会由于各种原因，比如硬件故障，软件故障，网络问题，有些节点会进进出出。有新的节点加入进来，也有老的节点退出集群。这个时候，集群中其他机器需要感知到这种变化，然后根据这种变化做出对应的决策。
4.1 Master选举 Master选举则是ZooKeeper中最为经典的应用场景了。比如 HDFS 中 Active NameNode 的选举。在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某一台机器进行执行，其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个master选举便是这种场景下的碰到的主要问题。
利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster节点，最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群Master选举了。成功创建该节点的客户端所在的机器就成为了Master。同时，其他没有成功创建该节点的客户端，都会在该节点上注册一个子节点变更的 Watcher，用于监控当前 Master 机器是否存活，一旦发现当前的Master挂了，那么其他客户端将会重新进行 Master 选举。这样就实现了 Master 的动态选举。
4.2 集群机器监控 这通常用于那种对集群中机器状态，机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，往往有一个监控系统，实时检测集群机器是否存活。过去的做法通常是：监控系统通过某种手段（比如ping）定时检测每个机器，或者每个机器自己定时向监控系统汇报“我还活着”。这种做法可行，但是存在两个比较明显的问题：
 将会产生一定的时延（受心跳长短限制）; 当集群中的节点发生变更时，其余的节点都需要对维护的集群文件（状态表）进行修改，修改内容多。  利用ZooKeeper有两个特性，就可以实时另一种集群机器存活性监控系统：
 客户端在节点 x 上注册一个Watcher，那么如果x的子节点变化了，会通知该客户端。 创建EPHEMERAL类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。  例如，监控系统在/clusterServers节点上注册一个Watcher，以后每动态加机器，那么就往/clusterServers下创建一个 EPHEMERAL类型的节点：/clusterServers/{hostname}.</description>
    </item>
    
    <item>
      <title>Zookeeper应用场景</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/zookeeper/zookeeper%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/zookeeper/zookeeper%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</guid>
      <description>大致来说，zookeeper 的使用场景如下，我就举几个简单的，大家能说几个就好了：
 分布式协调 分布式锁 元数据/配置信息管理 HA 高可用性  分布式协调 这个其实是 zookeeper 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zookeeper 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zookeeper 上对某个节点的值注册个监听器，一旦 B 系统处理完了就修改 zookeeper 那个节点的值，A 系统立马就可以收到通知，完美解决。
分布式锁 举个栗子。对某一个数据连续发出两个修改操作，两台机器同时收到了请求，但是只能一台机器先执行完另外一个机器再执行。那么此时就可以使用 zookeeper 分布式锁，一个机器接收到了请求之后先获取 zookeeper 上的一把分布式锁，就是可以去创建一个 znode，接着执行操作；然后另外一个机器也尝试去创建那个 znode，结果发现自己创建不了，因为被别人创建了，那只能等着，等第一个机器执行完了自己再执行。
元数据/配置信息管理 zookeeper 可以用作很多系统的配置信息的管理，比如 kafka、storm 等等很多分布式系统都会选用 zookeeper 来做一些元数据、配置信息的管理，包括 dubbo 注册中心不也支持 zookeeper 么？
HA 高可用性 这个应该是很常见的，比如 hadoop、hdfs、yarn 等很多大数据系统，都选择基于 zookeeper 来开发 HA 高可用机制，就是一个重要进程一般会做主备两个，主进程挂了立马通过 zookeeper 感知到切换到备用进程。
参考 zookeeper 都有哪些使用场景？</description>
    </item>
    
    <item>
      <title>悲观锁和乐观锁</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/%E6%82%B2%E8%A7%82%E9%94%81%E5%92%8C%E4%B9%90%E8%A7%82%E9%94%81/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/%E6%82%B2%E8%A7%82%E9%94%81%E5%92%8C%E4%B9%90%E8%A7%82%E9%94%81/</guid>
      <description>悲观锁 共享锁、排他锁
 共享锁，也就是其他事务可以并发读（其他事务也需要加共享锁），但是不能写。
排它锁，其他事务不能并发写也不能并发读。
 乐观锁 乐观锁其实也不是实际的锁，甚至没有用到锁来实现并发控制，而是采取其他方式来判断能否修改数据。乐观锁一般是用户自己实现的一种锁机制，虽然没有用到实际的锁，但是能产生加锁的效果。
乐观锁基本都是基于 CAS（Compare and swap）算法来实现的。
主要有以下几种方式：
 版本号标记：在表中新增一个字段：version，用于保存版本号。获取数据的时候同时获取版本号，然后更新数据的时候用以下命令:update xxx set version=version+1,… where … version=&amp;quot;old version&amp;quot; and ....。这时候通过判断返回结果的影响行数是否为0来判断是否更新成功，更新失败则说明有其他请求已经更新了数据了。 时间戳标记：和版本号一样，只是通过时间戳来判断。一般来说很多数据表都会有更新时间这一个字段，通过这个字段来判断就不用再新增一个字段了。 待更新字段：如果没有时间戳字段，而且不想新增字段，那可以考虑用待更新字段来判断，因为更新数据一般都会发生变化，那更新前可以拿要更新的字段的旧值和数据库的现值进行比对，没有变化则更新。 所有字段标记：数据表所有字段都用来判断。这种相当于就、不仅仅对某几个字段做加锁了，而是对整个数据行加锁，只要本行数据发生变化，就不进行更新。  总结 悲观锁和乐观锁大部分场景下差异不大，一些独特场景下有一些差别，一般我们可以从如下几个方面来判断：
1.响应速度：如果需要非常高的响应速度，建议采用乐观锁方案，成功就执行，不成功就失败，不需要等待其他并发去释放锁
2.冲突频率：如果冲突频率非常高，建议采用悲观锁，保证成功率，如果冲突频率大，乐观锁会需要多次重试才能成功，代价比较大
3.重试代价：如果重试代价大，建议采用悲观锁
参考链接： 乐观锁与悲观锁各自适用场景是什么？
一文读懂数据库中的乐观锁和悲观锁和MVCC</description>
    </item>
    
    <item>
      <title>部署vue项目</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/nginx/%E9%83%A8%E7%BD%B2vue%E9%A1%B9%E7%9B%AE/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/nginx/%E9%83%A8%E7%BD%B2vue%E9%A1%B9%E7%9B%AE/</guid>
      <description>时常我们想通过path来区分项目，例如通过 http://xxxx/admin 访问我们的后台，如果vue是的mode是history，请注意如下配置：
 修改vue-config.js文件配置  module.exports = {publicPath: &amp;#34;&amp;#34;}; 修改路由route/index  const router = new Router({  base: &amp;#39;/admin/&amp;#39;, //路由模式为history模式时，base必须要加上;路由模式为hash模式时，base可加可不加  mode: &amp;#39;history&amp;#39;,  routes: [] } 此时，请求是形如 http://xxxx/admin/xxx.css，从而避免出现形如http://xxxx/xxx.css找不到资源的情况。</description>
    </item>
    
    <item>
      <title>查找重复元素</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/nowcoder/%E6%9F%A5%E6%89%BE%E9%87%8D%E5%A4%8D%E5%85%83%E7%B4%A0/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/nowcoder/%E6%9F%A5%E6%89%BE%E9%87%8D%E5%A4%8D%E5%85%83%E7%B4%A0/</guid>
      <description>找出数组 arr 中重复出现过的元素（不用考虑返回顺序）
示例1
输入 [1, 2, 4, 4, 3, 3, 1, 5, 3] 输出 [1, 3, 4] 将传入的数组arr中的每一个元素value当作另外一个新数组b的key，然后遍历arr去访问b[value]，若b[value]不存在，则将b[value]设置为1，若b[value]存在，则将其加1。可以想象，若arr中数组没有重复的元素，则b数组中所有元素均为1；若arr数组中存在重复的元素，则在第二次访问该b[value]时，b[value]会加1，其值就为2了。最后遍历b数组，将其值大于1的元素的key存入另一个数组a中，就得到了arr中重复的元素。
function duplicates(arr) {  //声明两个数组，a数组用来存放结果，b数组用来存放arr中每个元素的个数  var a = [],b = [];  //遍历arr，如果以arr中元素为下标的的b元素已存在，则该b元素加1，否则设置为1  for(var i = 0; i &amp;lt; arr.length; i++){  if(!b[arr[i]]){  b[arr[i]] = 1;  continue;  }  b[arr[i]]++;  }  //遍历b数组，将其中元素值大于1的元素下标存入a数组中  for(var i = 0; i &amp;lt; b.length; i++){  if(b[i] &amp;gt; 1){  a.</description>
    </item>
    
    <item>
      <title>常备知识点</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mq/kafka/%E5%B8%B8%E5%A4%87%E7%9F%A5%E8%AF%86%E7%82%B9/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mq/kafka/%E5%B8%B8%E5%A4%87%E7%9F%A5%E8%AF%86%E7%82%B9/</guid>
      <description>1. 生产消费模型 参考：Kafka生产者消费者模型</description>
    </item>
    
    <item>
      <title>底层数据结构</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/redis/%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/redis/%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</guid>
      <description>字符串: SDS
list: 元素少且小 👉🏿 ziplist , 元素多且大 👉🏿 双链表
hash: 元素少且小 👉🏿 ziplist , 元素多且大 👉🏿 hashtable
zset: 元素少且小 👉🏿 ziplist , 元素多且大 👉🏿 skiplist
set: 元素少且小 👉🏿 intset , 元素多且大 👉🏿 hashtable
 redis的hashtable使用拉链法解决冲突
 什么是跳跃表？
跳表是一种带多级索引的链表。
有序链表能以log(n)的时间复杂实现查找，但是空间复杂度是O(n)，也就是说，如果将包含 n 个结点的单链表构造成跳表，我们需要额外再用接近 n 个结点的存储空间。
答：跳表这种高效的数据结构，值得每一个程序员掌握
为什么使用压缩ziplist？
答：相较于双链表，节省了两个指针的空间。（pre_entry_length前驱数据项的大小。因为不用描述前驱的数据类型，描述较为简单）。相较于数组，ziplist的每个entry所占的内存大小可以不同，便于节省空间。
为什么list  hash  zset 在数据量大的时候不再使用ziplist？
答：难以获得大的连续的内存空间。
参考 图解redis五种数据结构底层实现(动图哦)
Redis 数据结构 ziplist
Redis源码分析-压缩列表ziplist</description>
    </item>
    
    <item>
      <title>调整Spring HandlerMapping的顺序</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/spring/%E8%B0%83%E6%95%B4spring-handlermapping%E7%9A%84%E9%A1%BA%E5%BA%8F/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/spring/%E8%B0%83%E6%95%B4spring-handlermapping%E7%9A%84%E9%A1%BA%E5%BA%8F/</guid>
      <description>当请求形如：/opendoc/jquery-1.10.2.min.js 的静态资源时，如果恰好存在匹配这个请求的Controller时，默认情况下，这个静态资源请求会被 RequestMappingHandlerMapping 分配给这个Controller处理，从而可能找不到静态资源，例如存在下面这样的Controller：
 @RequestMapping(value = &amp;#34;/{name}/{version}&amp;#34;, method = {RequestMethod.POST, RequestMethod.GET})  public void rest3(@PathVariable(&amp;#34;name&amp;#34;) String name, @PathVariable(&amp;#34;version&amp;#34;) String version,  HttpServletRequest request, HttpServletResponse response) {  this.doRest(name, version, request, response);  } 为了能正确匹配的静态资源，我们可以调整Spring HandlerMapping的顺序，让SimpleUrlHandlerMapping先于RequestMappingHandlerMapping去匹配请求，SimpleUrlHandlerMapping会返回一个用于加载静态资源的ResourceHttpRequestHandler
默认情况下RequestMappingHandlerMapping 先于SimpleUrlHandlerMapping匹配请求，DispatcherServlet中初始化HandlerMapping的顺序源码如下所示：
 	/** * Initialize the HandlerMappings used by this class. * &amp;lt;p&amp;gt;If no HandlerMapping beans are defined in the BeanFactory for this namespace, * we default to BeanNameUrlHandlerMapping. */ 	private void initHandlerMappings(ApplicationContext context) { 	this.</description>
    </item>
    
    <item>
      <title>对象初始化顺序</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E5%AF%B9%E8%B1%A1%E5%88%9D%E5%A7%8B%E5%8C%96%E9%A1%BA%E5%BA%8F/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E5%AF%B9%E8%B1%A1%E5%88%9D%E5%A7%8B%E5%8C%96%E9%A1%BA%E5%BA%8F/</guid>
      <description>父类静态成员变量、父类静态代码块 👉🏿 子类静态成员变量、子类静态代码块 👉🏿 父类成员变量、父类代码块 👉🏿 父类构造方法 👉🏿 子类成员变量、子类代码块 👉🏿 子类构造方法
Java中类及方法的加载顺序
Java类加载顺序</description>
    </item>
    
    <item>
      <title>泛型</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E6%B3%9B%E5%9E%8B/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E6%B3%9B%E5%9E%8B/</guid>
      <description>泛型的好处  提供了一种类型安全检测机制 提升程序可读性  通配符 通配符的出现是为了指定泛型中的类型范围。
通配符有 3 种形式。
 &amp;lt;?&amp;gt;被称作无限定的通配符。 &amp;lt;? extends T&amp;gt;被称作有上限的通配符。 &amp;lt;? super T&amp;gt;被称作有下限的通配符。   ? 其实代表的是未知类型，所以涉及到 ? 时的操作，一定与具体类型无关。
有人说，&amp;lt;?&amp;gt;提供了只读的功能，也就是它删减了增加具体类型元素的能力，只保留与具体类型无关的功能。它不管装载在这个容器内的元素是什么类型，它只关心元素的数量、容器是否为空？我想这种需求还是很常见的吧。
有同学可能会想，&amp;lt;?&amp;gt;既然作用这么渺小，那么为什么还要引用它呢？ 
个人认为，提高了代码的可读性，程序员看到这段代码时，就能够迅速对此建立极简洁的印象，能够快速推断源码作者的意图。
类型擦除 在泛型类被类型擦除的时候，之前泛型类中的类型参数部分如果没有指定上限，如 &amp;lt;T&amp;gt;则会被转译成普通的 Object 类型，如果指定了上限如 &amp;lt;T extends String&amp;gt;则类型参数就被替换成类型上限。
类型擦除带来的局限性 正常情况下，因为泛型的限制，编译器不让最后一行代码编译通过，因为类似不匹配，但是，基于对类型擦除的了解，利用反射，我们可以绕过这个限制。
那么，利用反射，我们绕过编译器去调用 add 方法。
public class ToolTest {    public static void main(String[] args) {  List&amp;lt;Integer&amp;gt; ls = new ArrayList&amp;lt;&amp;gt;();  ls.add(23); //	ls.add(&amp;#34;text&amp;#34;);  try {  Method method = ls.</description>
    </item>
    
    <item>
      <title>浮点数运算</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E6%B5%AE%E7%82%B9%E6%95%B0%E8%BF%90%E7%AE%97/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E6%B5%AE%E7%82%B9%E6%95%B0%E8%BF%90%E7%AE%97/</guid>
      <description>结论  Java中单精度和双精度采用IEEE 754表示，能有效运算的范围大致是小数点后7位和15位 如果Java中默认的float和double不能满足你的精度要求，可以用BigDecimal，理论上它的精度只受限制与机器内存 如果BigDecimal仍无法满足需求，例如是无限循环小数的运算，可考虑设计分数系统保证计算的精度  1. IEEE 754 精度上限 编程语言中的浮点数一般都是 32 位的单精度浮点数 float 和 64 位的双精度浮点数 double，部分语言会使用 float32 或者 float64 区分这两种不同精度的浮点数。想要使用有限的位数表示全部的实数是不可能的，不用说无限长度的小数和无理数，因为长度的限制，有限小数在浮点数中都无法精确的表示。
 单精度浮点数 float 总共包含 32 位，其中 1 位表示符号、8 位表示指数，最后 23 位表示小数； 双精度浮点数 double 总共包含 64 位，其中 1 位表示符号，11 位表示指数，最后 52 位表示小数；  我们以单精度浮点数 0.15625 为例:
通过上图中的公式 (sign * 2^{exp}* (1+fraction))可以将浮点数的二进制表示转换成十进制的小数。0.15625 虽然还可以用单精度的浮点数精确表示，但是 0.1 和 0.2 只能使用浮点数表示近似的值：
因为 0.2 和 0.1 只是指数稍有不同，所以上图中只展示了 0.1 对应的单精度浮点数，从上图的结果我们可以看出，0.1 和 0.2 在浮点数中只能用近似值来代替，精度十分有限，因为单精度浮点数的小数位为 23，双精度的小数位为 52，同时都隐式地包含首位的 1，所以它们的精度在十进制中分别是(log_{10}(2^{24})\approx 7.</description>
    </item>
    
    <item>
      <title>高性能无锁队列Disruptor</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/other/%E9%AB%98%E6%80%A7%E8%83%BD%E6%97%A0%E9%94%81%E9%98%9F%E5%88%97disruptor/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/other/%E9%AB%98%E6%80%A7%E8%83%BD%E6%97%A0%E9%94%81%E9%98%9F%E5%88%97disruptor/</guid>
      <description>1. JDK中的队列 在jdk中的队列都实现了java.util.Queue接口，在队列中又分为两类，一类是线程不安全的，ArrayDeque，LinkedList等等，还有一类都在java.util.concurrent包下属于线程安全，而在我们真实的环境中，我们的机器都是属于多线程，当多线程对同一个队列进行排队操作的时候，如果使用线程不安全会出现，覆盖数据，数据丢失等无法预测的事情，所以我们这个时候只能选择线程安全的队列。在jdk中提供的线程安全的队列下面简单列举部分队列:
   队列名字 是否加锁 数据结构 关键技术点 是否有锁 是否有界     ArrayBlockingQueue 是 数组array ReentrantLock 有锁 有界   LinkedBlockingQueue 是 链表 ReentrantLock 有锁 有界   LinkedTransferQueue 否 链表 CAS 无锁 无界   ConcurrentLinkedQueue 否 链表 CAS 无锁 无界    我们可以看见，我们无锁的队列是无界的，有锁的队列是有界的，这里就会涉及到一个问题，我们在真正的线上环境中，无界的队列，对我们系统的影响比较大，有可能会导致我们内存直接溢出，所以我们首先得排除无界队列，当然并不是无界队列就没用了，只是在某些场景下得排除。其次还剩下ArrayBlockingQueue，LinkedBlockingQueue两个队列，他们两个都是用ReentrantLock控制的线程安全，他们两个的区别一个是数组，一个是链表，在队列中，一般获取这个队列元素之后紧接着会获取下一个元素，或者一次获取多个队列元素都有可能，而数组在内存中地址是连续的，在操作系统中会有缓存的优化(下面也会介绍缓存行)，所以访问的速度会略胜一筹，我们也会尽量去选择ArrayBlockingQueue。而事实证明在很多第三方的框架中，比如早期的log4j异步，都是选择的ArrayBlockingQueue。
当然ArrayBlockingQueue，也有自己的弊端，就是性能比较低，为什么jdk会增加一些无锁的队列，其实就是为了增加性能，很苦恼，又需要无锁，又需要有界，这个时候恐怕会忍不住说一句你咋不上天呢？但是还真有人上天了。
2.Disruptor Disruptor就是上面说的那个天，Disruptor是英国外汇交易公司LMAX开发的一个高性能队列，并且是一个开源的并发框架，并获得2011Duke’s程序框架创新奖。能够在无锁的情况下实现网络的Queue并发操作，基于Disruptor开发的系统单线程能支撑每秒600万订单。目前，包括Apache Storm、Camel、Log4j2等等知名的框架都在内部集成了Disruptor用来替代jdk的队列，以此来获得高性能。
3.1为什么这么牛逼？ 上面已经把Disruptor吹出了花了，你肯定会产生疑问，他真的能有这么牛逼吗，我的回答是当然的，在Disruptor中有三大杀器:
  CAS
  消除伪共享
  RingBuffer
  有了这三大杀器，Disruptor才变得如此牛逼。
3.1.1 锁和CAS CAS实现无锁队列可以参考👉无锁队列的实现</description>
    </item>
    
    <item>
      <title>缓存雪崩和缓存穿透</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/redis/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E5%92%8C%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/redis/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E5%92%8C%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/</guid>
      <description>1. 缓存雪崩 1.1 什么是缓存雪崩？ 简介：缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。
1.2 有哪些解决办法？  事前：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。 事中：本地ehcache缓存 + hystrix限流&amp;amp;降级，避免MySQL崩掉 事后：利用 redis 持久化机制保存的数据尽快恢复缓存  2. 缓存穿透 2.1 什么是缓存穿透？ 缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。
2.1 有哪些解决办法？ 最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。
 缓存无效 key（解决请求的 key 变化不频繁的情况） : 如果缓存和数据库都查不到某个 key 的数据就写一个到 redis 中去并设置过期时间，具体命令如下：SET key value EX 10086。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建的不同的请求key，会导致 redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。 布隆过滤器（解决请求的 key 变化频繁且key非法）：布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在与海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，我会先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。总结一下就是下面这张图(这张图片不是我画的，为了省事直接在网上找的)：  但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。
 缓存预热（解决请求的 key 变化频繁且key合法）：提前将需要做缓存的数据放入redis，即缓存预热。  3.</description>
    </item>
    
    <item>
      <title>基于aspect实现注解</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/spring/%E5%9F%BA%E4%BA%8Easpect%E5%AE%9E%E7%8E%B0%E6%B3%A8%E8%A7%A3/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/spring/%E5%9F%BA%E4%BA%8Easpect%E5%AE%9E%E7%8E%B0%E6%B3%A8%E8%A7%A3/</guid>
      <description>在工作中，我们有时候需要将一些公共的功能封装，比如操作日志的存储，防重复提交等等。这些功能有些接口会用到，为了便于其他接口和方法的使用，做成自定义注解，侵入性更低一点。别人用的话直接注解就好。下面就来讲讲自定义注解这些事情。
1. @Target、@Retention、@Documented简介 java自定义注解的注解位于包：java.lang.annotation下。包含三个元注解@Target、@Retention、@Documented，即注解的注解。
@Target @Target:注解的作用目标。和枚举ElementType共同起作用
根据源码知道，可以配置多个作用目标。
@Documented @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.ANNOTATION_TYPE) public @interface Target {  /** * Returns an array of the kinds of elements an annotation type * can be applied to. * @return an array of the kinds of elements an annotation type * can be applied to */  ElementType[] value(); } 复制代码 ElementType的类型如下：
* @author Joshua Bloch  * @since 1.5  * @jls 9.6.4.1 @Target  * @jls 4.</description>
    </item>
    
    <item>
      <title>基于Redis的分布式锁实现</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/redis/%E5%9F%BA%E4%BA%8Eredis%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/redis/%E5%9F%BA%E4%BA%8Eredis%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/</guid>
      <description>使用 set key value ex/px 秒/毫秒 xx/nx 的命令实现分布式锁，存在多个client端加锁成功的极端情况。Redisson使用RedLock可以避免这个问题，其原理是多锁，例如对多个哨兵集群加不同的锁，只有超半数以上的哨兵集群反馈加锁成功才算加锁成功。另外，Redisson还通过WatchDog实现了锁续租。还实现了很多有用的数据结构（RedissonPriorityDeque）和分布式同步工具（RedissonCountDownLatch, RedissonSemaphore）
前言 本篇文章主要介绍基于Redis的分布式锁实现到底是怎么一回事，其中参考了许多大佬写的文章，算是对分布式锁做一个总结
分布式锁概览 在多线程的环境下，为了保证一个代码块在同一时间只能由一个线程访问，Java中我们一般可以使用synchronized语法和ReetrantLock去保证，这实际上是本地锁的方式。但是现在公司都是流行分布式架构，在分布式环境下，如何保证不同节点的线程同步执行呢？
实际上，对于分布式场景，我们可以使用分布式锁，它是控制分布式系统之间互斥访问共享资源的一种方式。
比如说在一个分布式系统中，多台机器上部署了多个服务，当客户端一个用户发起一个数据插入请求时，如果没有分布式锁机制保证，那么那多台机器上的多个服务可能进行并发插入操作，导致数据重复插入，对于某些不允许有多余数据的业务来说，这就会造成问题。而分布式锁机制就是为了解决类似这类问题，保证多个服务之间互斥的访问共享资源，如果一个服务抢占了分布式锁，其他服务没获取到锁，就不进行后续操作。大致意思如下图所示（不一定准确）：
分布式锁的特点 分布式锁一般有如下的特点：
 互斥性： 同一时刻只能有一个线程持有锁 可重入性： 同一节点上的同一个线程如果获取了锁之后能够再次获取锁 锁超时：和J.U.C中的锁一样支持锁超时，防止死锁 高性能和高可用： 加锁和解锁需要高效，同时也需要保证高可用，防止分布式锁失效 具备阻塞和非阻塞性：能够及时从阻塞状态中被唤醒  分布式锁的实现方式 我们一般实现分布式锁有以下几种方式：
 基于数据库 基于Redis 基于zookeeper  本篇文章主要介绍基于Redis如何实现分布式锁
Redis的分布式锁实现 1. 利用setnx+expire命令 (错误的做法) Redis的SETNX命令，setnx key value，将key设置为value，当键不存在时，才能成功，若键存在，什么也不做，成功返回1，失败返回0 。 SETNX实际上就是SET IF NOT Exists的缩写
因为分布式锁还需要超时机制，所以我们利用expire命令来设置，所以利用setnx+expire命令的核心代码如下：
public boolean tryLock(String key,String requset,int timeout) { Long result = jedis.setnx(key, requset); // result = 1时，设置成功，否则设置失败 if (result == 1L) { return jedis.</description>
    </item>
    
    <item>
      <title>剑指 Offer 09. 用两个栈实现队列</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-09.-%E7%94%A8%E4%B8%A4%E4%B8%AA%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-09.-%E7%94%A8%E4%B8%A4%E4%B8%AA%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/</guid>
      <description>class CQueue {  Stack&amp;lt;Integer&amp;gt; stack1;  Stack&amp;lt;Integer&amp;gt; stack2;   public CQueue() {  stack1 = new Stack();  stack2 = new Stack();  }   public void appendTail(int value) {  stack1.push(value);  }   public int deleteHead() {  if(stack2.isEmpty()){  while(stack1.isEmpty() == false){  stack2.push(stack1.pop());  }  }  if(stack2.isEmpty()){  return -1;  }else{  return stack2.pop();  }  } }  /** * Your CQueue object will be instantiated and called as such: * CQueue obj = new CQueue(); * obj.</description>
    </item>
    
    <item>
      <title>剑指 Offer 18. 删除链表的节点</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-18.-%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E7%9A%84%E8%8A%82%E7%82%B9/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-18.-%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E7%9A%84%E8%8A%82%E7%82%B9/</guid>
      <description>class Solution {  public ListNode deleteNode(ListNode head, int val) {   ListNode myHead = new ListNode(-1);  myHead.next = head;   ListNode pos1 = head;  ListNode pos2 = myHead;   //定位  while (pos1.val != val) {  pos2 = pos1;  pos1 = pos1.next;  }  //删除  pos2.next = pos1.next;  return myHead.next;  } } 剑指 Offer 18. 删除链表的节点</description>
    </item>
    
    <item>
      <title>剑指 Offer 27. 二叉树的镜像</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-27.-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%95%9C%E5%83%8F/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-27.-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%95%9C%E5%83%8F/</guid>
      <description>剑指 Offer 27. 二叉树的镜像
/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution {  public TreeNode mirrorTree(TreeNode root) {  if(root == null){  return root;  }  //TreeNode posL = root.left;  //TreeNode posR = root.right;  //root.left = posR;  //root.</description>
    </item>
    
    <item>
      <title>剑指 Offer 28. 对称的二叉树</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-28.-%E5%AF%B9%E7%A7%B0%E7%9A%84%E4%BA%8C%E5%8F%89%E6%A0%91/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-28.-%E5%AF%B9%E7%A7%B0%E7%9A%84%E4%BA%8C%E5%8F%89%E6%A0%91/</guid>
      <description>/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution {  public boolean isSymmetric(TreeNode root) {  if(root == null){return true;}  return isSymmetric2(root.left, root.right);  }  private boolean isSymmetric2(TreeNode left, TreeNode right){  if (left == null &amp;amp;&amp;amp; right == null){return true;}  if ((left == null &amp;amp;&amp;amp; right !</description>
    </item>
    
    <item>
      <title>剑指 Offer 30. 包含min函数的栈</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-30.-%E5%8C%85%E5%90%ABmin%E5%87%BD%E6%95%B0%E7%9A%84%E6%A0%88/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-30.-%E5%8C%85%E5%90%ABmin%E5%87%BD%E6%95%B0%E7%9A%84%E6%A0%88/</guid>
      <description>剑指 Offer 30. 包含min函数的栈
class MinStack {   Stack&amp;lt;Integer&amp;gt; stack1;  Stack&amp;lt;Integer&amp;gt; stack2;   /** initialize your data structure here. */  public MinStack() {  stack1 = new Stack();  stack2 = new Stack();  }   public void push(int x) {  stack1.push(x);  if(stack2.isEmpty()){  stack2.push(x);  }else if(x &amp;gt; stack2.peek()){  stack2.push(stack2.peek());  }else{  stack2.push(x);  }  }   public void pop() {  stack1.</description>
    </item>
    
    <item>
      <title>剑指 Offer 32 - I. 从上到下打印二叉树</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-32-i.-%E4%BB%8E%E4%B8%8A%E5%88%B0%E4%B8%8B%E6%89%93%E5%8D%B0%E4%BA%8C%E5%8F%89%E6%A0%91/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-32-i.-%E4%BB%8E%E4%B8%8A%E5%88%B0%E4%B8%8B%E6%89%93%E5%8D%B0%E4%BA%8C%E5%8F%89%E6%A0%91/</guid>
      <description>/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution {  public static int[] levelOrder(TreeNode root) {  ArrayList&amp;lt;Integer&amp;gt; list = new ArrayList&amp;lt;Integer&amp;gt;();  if (root == null) {  return new int[]{};  }  Queue&amp;lt;TreeNode&amp;gt; queue=new LinkedList&amp;lt;TreeNode&amp;gt;();  queue.add(root);  while(!queue.isEmpty()){  TreeNode node=queue.poll();  list.add(node.val);  if(node.</description>
    </item>
    
    <item>
      <title>剑指 Offer 32 - II. 从上到下打印二叉树 II</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-32-ii.-%E4%BB%8E%E4%B8%8A%E5%88%B0%E4%B8%8B%E6%89%93%E5%8D%B0%E4%BA%8C%E5%8F%89%E6%A0%91-ii/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-32-ii.-%E4%BB%8E%E4%B8%8A%E5%88%B0%E4%B8%8B%E6%89%93%E5%8D%B0%E4%BA%8C%E5%8F%89%E6%A0%91-ii/</guid>
      <description>剑指 Offer 32 - II. 从上到下打印二叉树 II
class Solution {  public List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; levelOrder(TreeNode root) {  Queue&amp;lt;TreeNode&amp;gt; queue = new LinkedList&amp;lt;&amp;gt;();  List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; res = new ArrayList&amp;lt;&amp;gt;();  if(root != null) queue.add(root);  while(!queue.isEmpty()) {  List&amp;lt;Integer&amp;gt; tmp = new ArrayList&amp;lt;&amp;gt;();  for(int i = queue.size(); i &amp;gt; 0; i--) {  TreeNode node = queue.poll();  tmp.add(node.val);  if(node.left != null) queue.add(node.left);  if(node.right != null) queue.add(node.right);  }  res.</description>
    </item>
    
    <item>
      <title>剑指 Offer 32 - III. 从上到下打印二叉树 III</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-32-iii.-%E4%BB%8E%E4%B8%8A%E5%88%B0%E4%B8%8B%E6%89%93%E5%8D%B0%E4%BA%8C%E5%8F%89%E6%A0%91-iii/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/algorithm/leetcode/%E5%89%91%E6%8C%87-offer-32-iii.-%E4%BB%8E%E4%B8%8A%E5%88%B0%E4%B8%8B%E6%89%93%E5%8D%B0%E4%BA%8C%E5%8F%89%E6%A0%91-iii/</guid>
      <description>剑指 Offer 32 - III. 从上到下打印二叉树 III
/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution {  public List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; levelOrder(TreeNode root) {   LinkedList&amp;lt;TreeNode&amp;gt; queue = new LinkedList&amp;lt;&amp;gt;();  if (root != null){  queue.add(root);  }  List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; res = new ArrayList&amp;lt;&amp;gt;();  while (!</description>
    </item>
    
    <item>
      <title>脚手架</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E8%84%9A%E6%89%8B%E6%9E%B6/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E8%84%9A%E6%89%8B%E6%9E%B6/</guid>
      <description>1. 什么是java脚手架 其实就是java工程模板，你可以把一些通用的组件抽象成一个模板，下次开发的时候基于这个模板开发，避免重复造轮子。像apache默认就提供了很多模板（archetype）
2. 创建archetype 假如你已经有了一个maven项目，想给该项目创建一个archetype模板。你需要cd 到项目根目录下执行(pom.xml同级目录)。
mvn archetype:create-from-project 执行完后，生成的target类似这样：
3. 生成archetype模板 先cd target/generated-sources/archetype/ 然后执行：
mvn install 执行成功后，执行crawl命令：
mvn archetype:crawl 在本地仓库的根目录生成archetype-catalog.xml骨架配置文件:
来看一看它里面的内容:
4. 使用archetype模板 执行mvn archetype:generate -DarchetypeCatalog=local从本地archetype模板中创建项目。
mvn archetype:generate -DarchetypeCatalog=local 然后会让你选择模板序号和groupId artifactId version和package信息：
至此，项目创建成功!
当然，也可以使用IDEA来帮我们用图形界面使用archetype模板创建项目：
这里的信息根据archetype-catalog.xml中的填写，如果是本地导入Repository可以不填或者填&amp;rsquo;local&amp;rsquo;。既然提到本地，那么自然可以想到，可以将脚手架发布到nexus私服。发布到私服可以参看这里：https://www.cnblogs.com/woshimrf/p/maven-artifact-demo.html</description>
    </item>
    
    <item>
      <title>零拷贝</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E9%9B%B6%E6%8B%B7%E8%B4%9D/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E9%9B%B6%E6%8B%B7%E8%B4%9D/</guid>
      <description>简介 零拷贝的“零”是指用户态和内核态间copy数据的次数为零。
传统的数据copy（文件到文件、client到server等）涉及到四次用户态内核态切换、四次copy。四次copy中，两次在用户态和内核态间copy需要CPU参与、两次在内核态与IO设备间copy为DMA方式不需要CPU参与。零拷贝避免了用户态和内核态间的copy、减少了Java零拷贝机制解析核态间的切换。
 DMA(Direct Memory Access，直接内存存取) 是所有现代电脑的重要特色，它允许不同速度的硬件装置来沟通，而不需要依赖于CPU 的大量中断负载。 DMA控制器，接管了数据读写请求，减少CPU的负担。这样一来，CPU能高效工作了。 现代硬盘基本都支持DMA。
 使用Zero Copy前后对比：
使用前：
使用后：
Linux支持的(常见)零拷贝 mmap内存映射 sendfile Sendfile With DMA Scatter/Gather Copy splice
无论是传统IO方式，还是引入零拷贝之后，2次DMA copy 是都少不了的。因为两次DMA都是依赖硬件完成的。
实际上，零拷贝时有广义和狭义之分的。 广义零拷贝： 能减少拷贝次数，减少不必要的数据拷贝，就算作“零拷贝”。 这是目前，对零拷贝最为广泛的定义，我们需要知道的是，这是广义上的零拷贝，并不是操作系统 意义上的零拷贝。
Java零拷贝机制解析 Linux提供的领拷贝技术 Java并不是全支持，支持2种(内存映射mmap、sendfile)；
NIO提供的内存映射：MappedByteBuffer
NIO提供的sendfile：FileChannel.transferTo() FileChannel.transferFrom()
适用场景 数据不需要应用程序计算处理的场景，例如：访问静态资源
参考 Java中的零拷贝
Java零拷贝</description>
    </item>
    
    <item>
      <title>你了解的可见性可能是错的</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E4%BD%A0%E4%BA%86%E8%A7%A3%E7%9A%84%E5%8F%AF%E8%A7%81%E6%80%A7%E5%8F%AF%E8%83%BD%E6%98%AF%E9%94%99%E7%9A%84/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E4%BD%A0%E4%BA%86%E8%A7%A3%E7%9A%84%E5%8F%AF%E8%A7%81%E6%80%A7%E5%8F%AF%E8%83%BD%E6%98%AF%E9%94%99%E7%9A%84/</guid>
      <description>背景 这篇文章最开始再我的群里面有讨论过，当时想写的这篇文章的，但是因为一些时间的关系所以便没有写。最近阅读微信文章的时候发现了一篇零度写的一篇文章《分享一道阿里Java并发面试题》，对于有关Java并发性技术的文章我一般还是挺感兴趣的，于是阅读了一下，整体来说还是挺不错的，但是其中犯了一个验证可见性的问题。由于微信文章回复不方便讨论，于是我便把之前一些和群友的讨论在这里写出来。
如何测试可见性问题 因为在群里面我们习惯的有每周一问，也就由我或者群友发现一些由意思的问题然后提问给大家，让大家参与讨论，当时我提出了一个如何测试vlolatile可见性的问题，首先在Effective Java给出了一个测试volatile可见性的例子:
import java.util.concurrent.*;  public class Test {  private static /*volatile*/ boolean stop = false;  public static void main(String[] args) throws Exception {  Thread t = new Thread(new Runnable() {  public void run() {  int i = 0;  while (!stop) {  i++; // System.out.println(&amp;#34;hello&amp;#34;);  }  }  });  t.start();   Thread.sleep(1000);  TimeUnit.SECONDS.sleep(1);  System.out.println(&amp;#34;Stop Thread&amp;#34;);  stop = true;  } } 这里大家可以复制上面的代码，你会发现这里程序永远不会结束，在零度的那篇文章中也给出了一个测试可见性的例子:</description>
    </item>
    
    <item>
      <title>去除请求path前缀</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/nginx/%E5%8E%BB%E9%99%A4%E8%AF%B7%E6%B1%82path%E5%89%8D%E7%BC%80/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/nginx/%E5%8E%BB%E9%99%A4%E8%AF%B7%E6%B1%82path%E5%89%8D%E7%BC%80/</guid>
      <description>1. proxy_pass后面加根路径/ location ^~/user/ {  proxy_set_header Host $host;  proxy_set_header X-Real-IP $remote_addr;  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;  proxy_set_header X-NginX-Proxy true;   proxy_pass http://user/; } ^~/user/表示匹配前缀是user的请求，proxy_pass的结尾有/， 则会把/user/*后面的路径直接拼接到后面，即移除user。
2. 使用rewrite location ^~/user/ {  proxy_set_header Host $host;  proxy_set_header X-Real-IP $remote_addr;  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;  proxy_set_header X-NginX-Proxy true;   rewrite ^/user/(.*)$ /$1 break;  proxy_pass http://user; } 注意到proxy_pass结尾没有/， rewrite重写了url。
参考链接： Nginx代理proxy pass配置去除前缀
Nginx 转发域名地址报 400 Bad Request</description>
    </item>
    
    <item>
      <title>全文索引</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/other/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/other/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95/</guid>
      <description>全文索引 参考 什么是全文索引，为什么要使用全文索引
MySQL 之全文索引
浅谈mysql fulltext全文索引优缺点</description>
    </item>
    
    <item>
      <title>如何解决MySQL主从同步的延时问题</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3mysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%9A%84%E5%BB%B6%E6%97%B6%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3mysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%9A%84%E5%BB%B6%E6%97%B6%E9%97%AE%E9%A2%98/</guid>
      <description>你们有没有做 MySQL 读写分离？如何实现 MySQL 的读写分离？MySQL 主从复制原理的是啥？如何解决 MySQL 主从同步的延时问题？
如何实现 MySQL 的读写分离？ 其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。
MySQL 主从复制原理的是啥？ 主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。
这里有一个非常重要的一点，就是从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行 SQL 的特点，在高并发场景下，从库的数据一定会比主库慢一些，是有延时的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。
而且这里还有另外一个问题，就是如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。
所以 MySQL 实际上在这一块有两个机制，一个是半同步复制，用来解决主库数据丢失问题；一个是并行复制，用来解决主从同步延时问题。
这个所谓半同步复制，也叫 semi-sync 复制，指的就是主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了。
所谓并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。
MySQL 主从同步延时问题（精华） 以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。
是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了 2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。用户跟客服反馈，而客服就会反馈给我们。
我们通过 MySQL 命令：
show slave status 查看 Seconds_Behind_Master ，可以看到从库复制主库的数据落后了几 ms。
一般来说，如果主从延迟较为严重，有以下解决方案：
 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。（主库压力大导致延时） 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。（从库压力大导致延时） 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。（主从复制无法避免的延时） 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询设置直连主库。不推荐这种方法，你要是这么搞，读写分离的意义就丧失了。（主从复制无法避免的延时）  参考 你们有没有做 MySQL 读写分离？如何实现 MySQL 的读写分离？MySQL 主从复制原理的是啥？如何解决 MySQL 主从同步的延时问题？</description>
    </item>
    
    <item>
      <title>深度图解Redis Cluster原理</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/redis/%E6%B7%B1%E5%BA%A6%E5%9B%BE%E8%A7%A3redis-cluster%E5%8E%9F%E7%90%86/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/redis/%E6%B7%B1%E5%BA%A6%E5%9B%BE%E8%A7%A3redis-cluster%E5%8E%9F%E7%90%86/</guid>
      <description>主从能实现读能力进行扩展，但无法自动故障切换、写能力和存储能力；
哨兵能自动故障切换，但无法对写能力和存储能力是无法进行扩展；
集群能读能力、写能力、存储能力进行扩展，也能自动故障切换
前言 上文我们聊了基于Sentinel的Redis高可用架构，了解了Redis基于读写分离的主从架构，同时也知道当Redis的master发生故障之后，Sentinel集群是如何执行failover的，以及其执行failover的原理是什么。
这里大概再提一下，Sentinel集群会对Redis的主从架构中的Redis实例进行监控，一旦发现了master节点宕机了，就会选举出一个Sentinel节点来执行故障转移，从原来的slave节点中选举出一个，将其提升为master节点，然后让其他的节点去复制新选举出来的master节点。
你可能会觉得这样没有问题啊，甚至能够满足我们生产环境的使用需求了，那我们为什么还需要Redis Cluster呢？
1. 为什么需要Redis Cluster 的确，在数据上，有replication副本做保证；可用性上，master宕机会自动的执行failover。
 那问题在哪儿呢？
 首先Redis Sentinel说白了也是基于主从复制，在主从复制中slave的数据是完全来自于master。
假设master节点的内存只有4G，那slave节点所能存储的数据上限也只能是4G。而且在之前的跟随杠精的视角一起来了解Redis的主从复制文章中也说过，主从复制架构中是读写分离的，我们可以通过增加slave节点来扩展主从的读并发能力，但是写能力和存储能力是无法进行扩展的，就只能是master节点能够承载的上限。
所以，当你只需要存储4G的数据时候的，基于主从复制和基于Sentinel的高可用架构是完全够用的。
但是如果当你面临的是海量的数据的时候呢？16G、64G、256G甚至1T呢？现在互联网的业务里面，如果你的体量足够大，我觉得是肯定会面临缓存海量缓存数据的场景的。
这就是为什么我们需要引入Redis Cluster。
2. Redis Cluster是什么 知道了为什么需要Redis Cluster之后，我们就可以来对其一探究竟了。
 那什么是Redis Cluster呢？
 很简单，你就可以理解为n个主从架构组合在一起对外服务。Redis Cluster要求至少需要3个master才能组成一个集群，同时每个master至少需要有一个slave节点。
这样一来，如果一个主从能够存储32G的数据，如果这个集群包含了两个主从，则整个集群就能够存储64G的数据。
我们知道，主从架构中，可以通过增加slave节点的方式来扩展读请求的并发量，那Redis Cluster中是如何做的呢？虽然每个master下都挂载了一个slave节点，但是在Redis Cluster中的读、写请求其实都是在master上完成的。
slave节点只是充当了一个数据备份的角色，当master发生了宕机，就会将对应的slave节点提拔为master，来重新对外提供服务。
3. 节点负载均衡 知道了什么是Redis Cluster，我们就可以继续下面的讨论了。
不知道你思考过一个问题没，这么多的master节点。我存储的时候，到底该选择哪个节点呢？一般这种负载均衡算法，会选择哈希算法。哈希算法是怎么做的呢？
首先就是对key计算出一个hash值，然后用哈希值对master数量进行取模。由此就可以将key负载均衡到每一个Redis节点上去。这就是简单的哈希算法的实现。
那Redis Cluster是采取的上面的哈希算法吗？答案是没有。
Redis Cluster其实采取的是类似于一致性哈希的算法来实现节点选择的。那为什么不用哈希算法来进行实例选择呢？以及为什么说是类似的呢？我们继续讨论。
因为如果此时某一台master发生了宕机，那么此时会导致Redis中所有的缓存失效。为什么是所有的？假设之前有3个master，那么之前的算法应该是 hash % 3，但是如果其中一台master宕机了，则算法就会变成 hash % 2，会影响到之前存储的所有的key。而这对缓存后面保护的DB来说，是致命的打击。
4. 什么是一致性哈希 知道了通过传统哈希算法来实现对节点的负载均衡的弊端，我们就需要进一步了解什么是一致性哈希。
我们上面提过哈希算法是对master实例数量来取模，而一致性哈希则是对2^32取模，也就是值的范围在[0, 2^32 -1]。一致性哈希将其范围抽象成了一个圆环，使用CRC16算法计算出来的哈希值会落到圆环上的某个地方。
然后我们的Redis实例也分布在圆环上，我们在圆环上按照顺时针的顺序找到第一个Redis实例，这样就完成了对key的节点分配。我们举个例子。
假设我们有A、B、C三个Redis实例按照如图所示的位置分布在圆环上，此时计算出来的hash值，取模之后位置落在了位置D，那么我们按照顺时针的顺序，就能够找到我们这个key应该分配的Redis实例B。同理如果我们计算出来位置在E，那么对应选择的Redis的实例就是A。
即使这个时候Redis实例B挂了，也不会影响到实例A和C的缓存。
例如此时节点B挂了，那之前计算出来在位置D的key，此时会按照顺时针的顺序，找到节点C。相当于自动的把原来节点B的流量给转移到了节点C上去。而其他原本就在节点A和节点C的数据则完全不受影响。
这就是一致性哈希，能够在我们后续需要新增节点或者删除节点的时候，不影响其他节点的正常运行。
5. 虚拟节点机制 但是一致性哈希也存在自身的小问题，例如当我们的Redis节点分布如下时，就有问题了。
此时数据落在节点A上的概率明显是大于其他两个节点的，其次落在节点C上的概率最小。这样一来会导致整个集群的数据存储不平衡，AB节点压力较大，而C节点资源利用不充分。为了解决这个问题，一致性哈希算法引入了虚拟节点机制。</description>
    </item>
    
    <item>
      <title>生产问题定位</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/</guid>
      <description>排除应用之外的影响因素： top(cpu)、free(内存)、df(磁盘)、dstat(网络流量)、pstack、vmstat、st1race(底层系统调用)
  top 定位CPU 最高的进程
  top -Hp pid 定位使用 CPU 最高的线程（或者 ps -mp pid -o THREAD,tid,time）
  printf &#39;0x%x&#39; tid 线程 id 转化 16 进制
  jstack pid | grep tid 找到线程堆栈
5.1 gc线程（如下是查看gc情况的几种方式）
👉🏿 查看gc 日志
👉🏿 jstat -gcutil 进程号 统计间隔毫秒 统计次数（缺省代表一次统计）
👉🏿 如果所在公司有对应用进行监控的组件当然更方便（比如Prometheus + Grafana）
 结合内存dump日志分析：
  哪些对象导致的内存溢出导致频繁gc（尤其是full gc）
  如果不是内存溢出导致频繁gc，也可能是代码或者第三方依赖的包中有显示的System.gc()调用，此时可以通过添加 -XX:+DisableExplicitGC来禁用JVM对显示GC的响应。
在分配堆外内存的时候，内存不足时会显示的调用System.gc()，如果显示gc被禁用，则可能会导致堆外内存溢出，所以堆外内存的回收最好就不要依赖jvm，主动回收吧。
   5.2 业务线程</description>
    </item>
    
    <item>
      <title>实现线程超时的几种方式</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E8%B6%85%E6%97%B6%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E8%B6%85%E6%97%B6%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</guid>
      <description>1. 基于线程的join(long millis)方法 其实这个方法比较牵强，因为它主要作用是用来多个线程之间进行同步的。但因为它提供了这个带参数的方法（所以这也给了我们一个更广泛的思路，就是一般带有超时参数的方法我们都可以尝试着用它来实现超时结束任务），所以我们可以用它来实现。注意这里的参数的单位是固定的毫秒，不同于接下来的带单位的函数。具体用法请看示例：
public class JoinTest {  public static void main(String[] args) {  Task task1 = new Task(&amp;#34;one&amp;#34;, 4);  Task task2 = new Task(&amp;#34;two&amp;#34;, 2);  Thread t1 = new Thread(task1);  Thread t2 = new Thread(task2);  t1.start();  try {  t1.join(2000); // 在主线程中等待t1执行2秒  } catch (InterruptedException e) {  System.out.println(&amp;#34;t1 interrupted when waiting join&amp;#34;);  e.printStackTrace();  }  t1.interrupt(); // 这里很重要，一定要打断t1,因为它已经执行了2秒。  t2.</description>
    </item>
    
    <item>
      <title>事务传播实战</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/spring/%E4%BA%8B%E5%8A%A1%E4%BC%A0%E6%92%AD%E5%AE%9E%E6%88%98/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/spring/%E4%BA%8B%E5%8A%A1%E4%BC%A0%E6%92%AD%E5%AE%9E%E6%88%98/</guid>
      <description>参考链接： 手把手带你实战下Spring的七种事务传播行为
Spring的PROPAGATION_NESTED和PROPAGATION_REQUIRES_NEW的区别？</description>
    </item>
    
    <item>
      <title>事务隔离级别和实现原理</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E5%92%8C%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E5%92%8C%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</guid>
      <description>事务具有原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）四个特性，简称 ACID，缺一不可。原子性由undo log保证，持久性由redo log保证，今天要说的就是隔离性。
标准SQL通过行共享锁、行排他锁、表共享锁、表排他锁实现四种事务隔离级别，InnoDB事务在RU, S 两种隔离级别实现原理和标准SQL差不多，在RC级别它通过MVCC提前标准SQL一个级别解决了不可重复读，在RR级别通过间隙锁提前标准SQL一个隔离级别解决了幻读。（MVCC: 为了不加锁解决读写冲突的问题）
1. 概念说明 以下几个概念是事务隔离级别要实际解决的问题，所以需要搞清楚都是什么意思。
脏读 脏读指的是读到了其他事务未提交的数据，未提交意味着这些数据可能会回滚，也就是可能最终不会存到数据库中，也就是不存在的数据。读到了并一定最终存在的数据，这就是脏读。
可重复读 可重复读指的是在一个事务内，最开始读到的数据和事务结束前的任意时刻读到的同一批数据都是一致的。通常针对数据**更新（UPDATE）**操作。
不可重复读 对比可重复读，不可重复读指的是在同一事务内，不同的时刻读到的同一批数据可能是不一样的，可能会受到其他事务的影响，比如其他事务改了这批数据并提交了。通常针对数据**更新（UPDATE）**操作。
幻读 幻读是针对数据**插入（INSERT）**操作来说的。假设事务A对某些行的内容作了更改，但是还未提交，此时事务B插入了与事务A更改前的记录相同的记录行，并且在事务A提交之前先提交了，而这时，在事务A中查询，会发现好像刚刚的更改对于某些数据未起作用，但其实是事务B刚插入进来的，让用户感觉很魔幻，感觉出现了幻觉，这就叫幻读。
2. 事务隔离级别 SQL 标准定义了四种隔离级别，MySQL 全都支持。这四种隔离级别分别是：
 读未提交（READ UNCOMMITTED） 读提交 （READ COMMITTED） 可重复读 （REPEATABLE READ） 串行化 （SERIALIZABLE）  从上往下，隔离强度逐渐增强，性能逐渐变差。采用哪种隔离级别要根据系统需求权衡决定，其中，可重复读是 MySQL 的默认级别。
事务隔离其实就是为了解决上面提到的脏读、不可重复读、幻读这几个问题，下面展示了 4 种隔离级别对这三个问题的解决程度。
只有串行化的隔离级别解决了全部这 3 个问题，其他的 3 个隔离级别都有缺陷。
3. 标准SQL事务隔离级别实现原理 我们上面遇到的问题其实就是并发事务下的控制问题，解决并发事务的最常见方式就是悲观并发控制了（也就是数据库中的锁）。标准SQL事务隔离级别的实现是依赖锁的，我们来看下具体是怎么实现的：
   事务隔离级别 实现方式     未提交读（RU） 事务对当前被读取的数据不加锁；事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级共享锁，直到事务结束才释放。   提交读（RC） 事务对当前被读取的数据加行级共享锁（当读到时才加锁），一旦读完该行，立即释放该行级共享锁；事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级排他锁，直到事务结束才释放。   可重复读（RR） 事务在读取某数据的瞬间（就是开始读取的瞬间），必须先对其加行级共享锁，直到事务结束才释放；事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级排他锁，直到事务结束才释放。   序列化读（S） 事务在读取数据时，必须先对其加表级共享锁 ，直到事务结束才释放；事务在更新数据时，必须先对其加表级排他锁 ，直到事务结束才释放。    可以看到，在只使用锁来实现隔离级别的控制的时候，需要频繁的加锁解锁，而且很容易发生读写的冲突（例如在RC级别下，事务A更新了数据行1，事务B则在事务A提交前读取数据行1都要等待事务A提交并释放锁）。</description>
    </item>
    
    <item>
      <title>锁</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E9%94%81/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E9%94%81/</guid>
      <description>阿里面试，问了我乐观锁、悲观锁、AQS、sync和Lock，这个回答让我拿了offer
阿里面试官：说一下公平锁和非公平锁的区别？</description>
    </item>
    
    <item>
      <title>为什么需要protobuf</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/other/%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81protobuf/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/other/%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81protobuf/</guid>
      <description>为什么需要protobuf  protobuf采用字节编码，而json, xml都是字符编码，字节编码更加节省空间 采用了varint编码，进一步降低了编码后的空间大小  Varint就是一种对数字进行编码的方法，编码后二进制数据是不定长的，数值越小的数字使用的字节数越少。例如对于int32_t，采用Varint编码后需要1~5个bytes，小的数字使用1个byte，大的数字使用5个bytes。基于实际场景中小数字的使用远远多于大数字，因此通过Varint编码对于大部分场景都可以起到一个压缩的效果。</description>
    </item>
    
    <item>
      <title>线程安全的单例的几种实现方法</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E5%8D%95%E4%BE%8B%E7%9A%84%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E5%8D%95%E4%BE%8B%E7%9A%84%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95/</guid>
      <description>1. 使用synchronized 饱汉：双重检查锁定、饿汉、静态内部类、枚举 都属于利用synchronized同步原理实现
1.1 饱汉：双重检查锁定（double-checked locking） public class SingleTon {   // 静态实例变量加上volatile  private static volatile SingleTon instance;   // 私有化构造函数  private SingleTon() {}   // 双重检查锁  public static SingleTon getInstance() {  if (instance == null) {  synchronized(SingleTon.class){  if(instance == null){  instance = new SingleTon();  }  }  }  return instance;  } 1.2 饿汉 public class Singleton {  private static Singleton instance = new Singleton();   private Singleton() {  }   public static Singleton getInstance() {  return instance;  } } 1.</description>
    </item>
    
    <item>
      <title>线程状态</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/java/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81/</guid>
      <description>Linux线程的状态与调度 Java线程的6种状态及切换 Java 线程的生命周期中，在 Thread 类里有一个枚举类型 State，定义了线程的几种状态，分别有：
 New Runnable Blocked Waiting Timed Waiting Terminated  上图有误，根据Blocked注释可知：线程从Waiting或Timed Waiting状态恢复后，应该是去到Blocked状态
 Thread state for a thread blocked waiting for a monitor lock. A thread in the blocked state is waiting for a monitor lock to enter a synchronized block/method or reenter a synchronized block/method after calling Object.wait.
 sleep和wait区别 1、sleep方法是Thread类的静态方法；
wait方法是Object类的成员方法
2、sleep方法使当前线程暂停执行指定的时间，让出cpu给其他线程，但是它的监控状态依然保持着，当指定的时间到了又会自动恢复运行状态。在调用sleep方法后，线程不会释放对象锁；
而当调用wait方法时，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用notify()方法后本线程才进入对象锁定池处于准备状态。
3、sleep方法有可能会抛出异常，所以需要进行异常处理；
wait方法不需要处理
4、sleep方法可以在任何地方使用；
wait方法只能在同步方法和同步代码块中使用
参考 Linux线程的状态与调度</description>
    </item>
    
    <item>
      <title>一个SQL执行的很慢</title>
      <link>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/%E4%B8%80%E4%B8%AAsql%E6%89%A7%E8%A1%8C%E7%9A%84%E5%BE%88%E6%85%A2/</link>
      <pubDate>Fri, 27 Aug 2021 11:15:10 +0800</pubDate>
      
      <guid>https://xuzhijvn.github.io/zh-cn/posts/code/mysql/%E4%B8%80%E4%B8%AAsql%E6%89%A7%E8%A1%8C%E7%9A%84%E5%BE%88%E6%85%A2/</guid>
      <description>一个SQL执行的很慢，我们要分两种情况讨论：
大多数情况下很正常，偶尔很慢  数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。  当我们要往数据库插入一条数据、或者要更新一条数据的时候，我们知道数据库会在内存中把对应字段的数据更新了，但是更新之后，这些更新的字段并不会马上同步持久化到磁盘中去，而是把这些更新的记录写入到 redo log 日记中去，等到空闲的时候，在通过 redo log 里的日记把最新的数据同步到磁盘中去。写redo log是顺序io
 执行的时候，遇到锁，如表锁、行锁。  这条 SQL 语句一直执行的很慢  没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。 数据库选错了索引。  参考 腾讯面试：一条SQL语句执行得很慢的原因有哪些？&amp;mdash;不看后悔系列</description>
    </item>
    
  </channel>
</rss>
